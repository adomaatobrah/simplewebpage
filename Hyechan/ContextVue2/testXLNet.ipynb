{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wordfreq\n",
    "import math\n",
    "from transformers import XLNetTokenizer, XLNetLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ka37/code/transformers/src/transformers/configuration_xlnet.py:206: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model = XLNetLMHeadModel.from_pretrained(\"xlnet-base-cased\")\n",
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "origStr = \"I mean, when you go to a movie and it’s set to start at a certain time, would you not be upset if 7 hours later said movie has not started?\"\n",
    "# \"<mask> <mask> <mask> <mask> <mask> <mask> a <mask> and <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask>?\"\n",
    "testStr = \"I mean, when you go to a <mask> and it’s set to start at a certain time, would you not be upset if 7 hours later said movie has not started?\"\n",
    "encoded_str = tokenizer.encode(testStr)\n",
    "tokens_tensor = torch.tensor([encoded_str])\n",
    "tokenizer.convert_ids_to_tokens(encoded_str)\n",
    "perm_mask = torch.zeros((1, tokens_tensor.shape[1], tokens_tensor.shape[1]), dtype=torch.float)\n",
    "perm_mask[:, :, 8] = 1.0  # Previous tokens don't see masked token\n",
    "target_mapping = torch.zeros((1, 1, tokens_tensor.shape[1]), dtype=torch.float)  # Shape [1, 1, seq_length] => let's predict one token\n",
    "target_mapping[0, 0, 8] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetLMHeadModel(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_loss): Linear(in_features=768, out_features=32000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
       "         -6.1461e-03,  3.4621e-02],\n",
       "        [ 3.8088e-02,  1.9711e-02,  2.6418e-02,  ..., -1.9814e-04,\n",
       "         -3.4959e-02,  2.6332e-02],\n",
       "        [ 2.7695e-02,  1.7981e-02,  1.9903e-02,  ..., -1.8557e-03,\n",
       "         -3.7725e-02,  3.1554e-02],\n",
       "        ...,\n",
       "        [ 4.6112e-02,  1.1896e-01,  1.3977e-02,  ...,  6.2643e-02,\n",
       "          3.9860e-02, -4.7146e-02],\n",
       "        [ 6.4509e-02,  1.2249e-01, -2.3139e-02,  ..., -6.4272e-02,\n",
       "          4.0406e-02,  2.5219e-01],\n",
       "        [ 4.0150e-03, -4.8572e-02, -2.2838e-02,  ..., -2.1984e-02,\n",
       "          4.1460e-02,  1.1334e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.word_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_loss.weight is model.transformer.word_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.8919e-03,  6.5530e-02, -1.5061e-02,  ..., -4.5812e-02,\n",
       "         -6.1461e-03,  3.4621e-02],\n",
       "        [ 3.8088e-02,  1.9711e-02,  2.6418e-02,  ..., -1.9814e-04,\n",
       "         -3.4959e-02,  2.6332e-02],\n",
       "        [ 2.7695e-02,  1.7981e-02,  1.9903e-02,  ..., -1.8557e-03,\n",
       "         -3.7725e-02,  3.1554e-02],\n",
       "        ...,\n",
       "        [ 4.6112e-02,  1.1896e-01,  1.3977e-02,  ...,  6.2643e-02,\n",
       "          3.9860e-02, -4.7146e-02],\n",
       "        [ 6.4509e-02,  1.2249e-01, -2.3139e-02,  ..., -6.4272e-02,\n",
       "          4.0406e-02,  2.5219e-01],\n",
       "        [ 4.0150e-03, -4.8572e-02, -2.2838e-02,  ..., -2.1984e-02,\n",
       "          4.1460e-02,  1.1334e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.transformer.word_embedding.weight\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_embeddings = embeddings.detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32000, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings.copy_(torch.tensor(orig_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05505202"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_std = orig_embeddings.std()\n",
    "orig_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Var[X] = v\n",
    "Var[a X] = a^2 v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0006)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = torch.randn_like(embeddings)\n",
    "noise *= orig_std * .01\n",
    "noise.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, perm_mask=perm_mask, target_mapping=target_mapping)\n",
    "    next_token_logits = outputs[0][0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32000])\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', '?', 's', 'sion', '▁Note', 'c', 'p', '▁Formation', 'ions', 'sis']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer.convert_ids_to_tokens(index.item()) for index in next_token_logits.topk(10).indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', '?', 's', 'c', 'p', '▁Note', 'sion', '▁Formation', 'nch', 'm']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer.convert_ids_to_tokens(index.item()) for index in next_token_logits.topk(10).indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_TEXT = \"\"\"In 1991, the remains of Russian Tsar Nicholas II and his family\n",
    "(except for Alexei and Maria) are discovered.\n",
    "The voice of Nicholas's young son, Tsarevich Alexei Nikolaevich, narrates the\n",
    "remainder of the story. 1883 Western Siberia,\n",
    "a young Grigori Rasputin is asked by his father and a group of men to perform magic.\n",
    "Rasputin has a vision and denounces one of the men as a horse thief. Although his\n",
    "father initially slaps him for making such an accusation, Rasputin watches as the\n",
    "man is chased outside and beaten. Twenty years later, Rasputin sees a vision of\n",
    "the Virgin Mary, prompting him to become a priest. Rasputin quickly becomes famous,\n",
    "with people, even a bishop, begging for his blessing. <eod> </s> <eos>\"\"\"\n",
    "START_INDEX = 166 # TODO: change hard-coded value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLogProb(original_text, index, tokens_tensor, perm_mask, target_mapping):        \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, perm_mask=perm_mask, target_mapping=target_mapping)\n",
    "        next_token_logits = outputs[0][0, 0, :]\n",
    "\n",
    "    preds = [tokenizer.convert_ids_to_tokens(index.item()) for index in next_token_logits.topk(5).indices]\n",
    "    next_token_logprobs = next_token_logits - next_token_logits.logsumexp(0)\n",
    "    logProb = next_token_logprobs[tokenizer.convert_tokens_to_ids(original_text[index])].item()\n",
    "\n",
    "    return (preds, logProb, next_token_logprobs)\n",
    "\n",
    "def computePredsLogProbs(preds, next_token_logprobs):\n",
    "    predLogProbs = []\n",
    "    for i in preds:\n",
    "        predLogProbs.append(next_token_logprobs[tokenizer.convert_tokens_to_ids(i)].item())\n",
    "    return predLogProbs\n",
    "\n",
    "def bigContext(tokenized_text, index):\n",
    "    encoded_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([encoded_ids])\n",
    "    perm_mask = torch.zeros((1, tokens_tensor.shape[1], tokens_tensor.shape[1]), dtype=torch.float)\n",
    "    perm_mask[:, :, index] = 1.0\n",
    "    target_mapping = torch.zeros((1, 1, tokens_tensor.shape[1]), dtype=torch.float)\n",
    "    target_mapping[0, 0, index] = 1.0\n",
    "    return computeLogProb(tokenized_text, index, tokens_tensor, perm_mask, target_mapping)\n",
    "\n",
    "def smallContext(tokenized_text, index):\n",
    "    tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(tokenized_text)])\n",
    "    perm_mask = torch.zeros((1, tokens_tensor.shape[1], tokens_tensor.shape[1]), dtype=torch.float)\n",
    "    for i in range(START_INDEX, len(tokenized_text) - 1):\n",
    "        if i != index - 1 and i != index + 1:\n",
    "            perm_mask[:, :, i] = 1.0\n",
    "    target_mapping = torch.zeros((1, 1, tokens_tensor.shape[1]), dtype=torch.float)\n",
    "    target_mapping[0, 0, index] = 1.0\n",
    "    return computeLogProb(tokenized_text, index, tokens_tensor, perm_mask, target_mapping)\n",
    "\n",
    "def noContext(word):\n",
    "    if word in '.?,:!;\\'\\\"‘’“”|-/\\\\':\n",
    "        return -1 # FIXME\n",
    "    freq = wordfreq.word_frequency(word, 'en')\n",
    "    if freq == 0:\n",
    "        print(\"word not found:\", word)\n",
    "        return -100\n",
    "    return math.log(freq)\n",
    "\n",
    "def compute_scores(input_text):\n",
    "    tokenized_text = tokenizer.tokenize(PADDING_TEXT + \" \" + input_text + \"</s>\", add_special_tokens=False, return_tensors='pt')\n",
    "\n",
    "    usedModels = [\"bigContext\", \"smallContext\", \"noContext\"]\n",
    "    results = []\n",
    "    compoundBigPreds = []\n",
    "    compoundSmallPreds = []\n",
    "    compoundBigLogProb = 0\n",
    "    compoundSmallLogProb = 0\n",
    "    currentWord = \"\"\n",
    "    startID = 0\n",
    "\n",
    "    # For each token not in PADDING_TEXT\n",
    "    for i in range(START_INDEX, len(tokenized_text) - 1):\n",
    "        # Compute the top 5 model predictions, the log probability of the\n",
    "        #   correct answer, and the next_token_logprobs\n",
    "        bigPreds, bigLogProb, bigNextLogProbs = bigContext(tokenized_text, i)\n",
    "        smallPreds, smallLogProb, smallNextLogProbs = smallContext(tokenized_text, i)\n",
    "\n",
    "        # Generate the log probabilities of the top 5 small model predictions\n",
    "        #   given big context vs. small context\n",
    "        bigPredsLogProbs = computePredsLogProbs(smallPreds, bigNextLogProbs)\n",
    "        smallPredsLogProbs = computePredsLogProbs(smallPreds, smallNextLogProbs)\n",
    "\n",
    "        # if the current token is a start token\n",
    "        if tokenized_text[i].startswith(\"▁\"):\n",
    "            compoundBigLogProb = bigLogProb\n",
    "            compoundSmallLogProb = smallLogProb\n",
    "            compoundBigPreds = bigPreds\n",
    "            compoundSmallPreds = smallPreds\n",
    "            currentWord = tokenized_text[i]\n",
    "            startID = i\n",
    "        # If the current token is a continuation token\n",
    "        else:\n",
    "            compoundBigLogProb += bigLogProb\n",
    "            compoundSmallLogProb += smallLogProb\n",
    "            currentWord += tokenized_text[i]\n",
    "        \n",
    "        # if the next token is not a start token or the end of sequence, don't do any more work\n",
    "        #   because that means the next token is a continuation token\n",
    "        if not (tokenized_text[i + 1].startswith(\"▁\") or tokenized_text[i + 1] == \"</s>\"):\n",
    "            continue\n",
    "            \n",
    "        currentWord = currentWord.replace(\"▁\", \"\")\n",
    "        \n",
    "        # Compute the no-context log probabilities of the current word and\n",
    "        #   the predictions generated by the small context model\n",
    "        noContextLogProb = noContext(currentWord)\n",
    "        noPredsLogProbs = []\n",
    "        for j in smallPreds:\n",
    "            processed_word = j.replace(\"▁\", \"\")\n",
    "            noPredsLogProbs.append(noContext(processed_word))\n",
    "\n",
    "        results.append(dict(\n",
    "            id = startID,\n",
    "            word=currentWord,\n",
    "            src=\"original\",\n",
    "            model=\"smallContext\",\n",
    "            score=compoundSmallLogProb)\n",
    "        )\n",
    "        \n",
    "        results.append(dict(\n",
    "            id = startID,\n",
    "            word=currentWord,\n",
    "            src=\"original\",\n",
    "            model=\"bigContext\",\n",
    "            score=compoundBigLogProb)\n",
    "        )\n",
    "\n",
    "        results.append(dict(\n",
    "            id = startID,\n",
    "            word=currentWord,\n",
    "            src=\"original\",\n",
    "            model=\"noContext\",\n",
    "            score=noContextLogProb)\n",
    "        )\n",
    "\n",
    "        for j in range(0, len(smallPreds)):\n",
    "            results.append(dict(\n",
    "                id = startID,\n",
    "                word=smallPreds[j],\n",
    "                src=\"smallContext\",\n",
    "                model=\"smallContext\",\n",
    "                score=smallPredsLogProbs[j])\n",
    "            )\n",
    "\n",
    "            results.append(dict(\n",
    "                id = startID,\n",
    "                word=smallPreds[j],\n",
    "                src=\"smallContext\",\n",
    "                model=\"bigContext\",\n",
    "                score=bigPredsLogProbs[j])\n",
    "            )\n",
    "            \n",
    "            results.append(dict(\n",
    "                id = startID,\n",
    "                word=smallPreds[j],\n",
    "                src=\"smallContext\",\n",
    "                model=\"noContext\",\n",
    "                score=noPredsLogProbs[j])\n",
    "            )\n",
    "        \n",
    "        compoundBigLogProb = 0\n",
    "        compoundSmallLogProb = 0\n",
    "        compoundBigPreds = []\n",
    "        compoundSmallPreds = []\n",
    "        currentWord = \"\"\n",
    "\n",
    "    return (results, usedModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'id': 0,\n",
       "   'word': 'Hello.',\n",
       "   'src': 'original',\n",
       "   'model': 'smallContext',\n",
       "   'score': -1.9449241161346436},\n",
       "  {'id': 0,\n",
       "   'word': 'Hello.',\n",
       "   'src': 'original',\n",
       "   'model': 'bigContext',\n",
       "   'score': -16.21267080307007},\n",
       "  {'id': 0,\n",
       "   'word': 'Hello.',\n",
       "   'src': 'original',\n",
       "   'model': 'noContext',\n",
       "   'score': -9.877819805787551},\n",
       "  {'id': 0,\n",
       "   'word': '.',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -0.25174784660339355},\n",
       "  {'id': 0,\n",
       "   'word': '.',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -2.8212952613830566},\n",
       "  {'id': 0,\n",
       "   'word': '.',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 0,\n",
       "   'word': '?',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -2.0876107215881348},\n",
       "  {'id': 0,\n",
       "   'word': '?',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -1.3548493385314941},\n",
       "  {'id': 0,\n",
       "   'word': '?',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 0,\n",
       "   'word': '!',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -2.7751107215881348},\n",
       "  {'id': 0,\n",
       "   'word': '!',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -2.4268317222595215},\n",
       "  {'id': 0,\n",
       "   'word': '!',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 0,\n",
       "   'word': '▁',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -4.991657733917236},\n",
       "  {'id': 0,\n",
       "   'word': '▁',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -0.9000425338745117},\n",
       "  {'id': 0,\n",
       "   'word': '▁',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 0,\n",
       "   'word': '\"',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -5.210697650909424},\n",
       "  {'id': 0,\n",
       "   'word': '\"',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -5.428391933441162},\n",
       "  {'id': 0,\n",
       "   'word': '\"',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 3,\n",
       "   'word': 'This',\n",
       "   'src': 'original',\n",
       "   'model': 'smallContext',\n",
       "   'score': -0.6132526397705078},\n",
       "  {'id': 3,\n",
       "   'word': 'This',\n",
       "   'src': 'original',\n",
       "   'model': 'bigContext',\n",
       "   'score': -8.23533821105957},\n",
       "  {'id': 3,\n",
       "   'word': 'This',\n",
       "   'src': 'original',\n",
       "   'model': 'noContext',\n",
       "   'score': -5.065619602429015},\n",
       "  {'id': 3,\n",
       "   'word': '▁This',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -0.6132526397705078},\n",
       "  {'id': 3,\n",
       "   'word': '▁This',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -8.23533821105957},\n",
       "  {'id': 3,\n",
       "   'word': '▁This',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -5.065619602429015},\n",
       "  {'id': 3,\n",
       "   'word': '.',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -1.2362241744995117},\n",
       "  {'id': 3,\n",
       "   'word': '.',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -4.450054168701172},\n",
       "  {'id': 3,\n",
       "   'word': '.',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 3,\n",
       "   'word': '?',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -3.0712709426879883},\n",
       "  {'id': 3,\n",
       "   'word': '?',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -5.026655197143555},\n",
       "  {'id': 3,\n",
       "   'word': '?',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 3,\n",
       "   'word': '▁this',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -3.3679018020629883},\n",
       "  {'id': 3,\n",
       "   'word': '▁this',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -8.657590866088867},\n",
       "  {'id': 3,\n",
       "   'word': '▁this',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -5.065619602429015},\n",
       "  {'id': 3,\n",
       "   'word': ',',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -4.258139610290527},\n",
       "  {'id': 3,\n",
       "   'word': ',',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -3.4683456420898438},\n",
       "  {'id': 3,\n",
       "   'word': ',',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 4,\n",
       "   'word': 'is',\n",
       "   'src': 'original',\n",
       "   'model': 'smallContext',\n",
       "   'score': -0.0007877349853515625},\n",
       "  {'id': 4,\n",
       "   'word': 'is',\n",
       "   'src': 'original',\n",
       "   'model': 'bigContext',\n",
       "   'score': -0.0713052749633789},\n",
       "  {'id': 4,\n",
       "   'word': 'is',\n",
       "   'src': 'original',\n",
       "   'model': 'noContext',\n",
       "   'score': -4.4654082436129325},\n",
       "  {'id': 4,\n",
       "   'word': '▁is',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -0.0007877349853515625},\n",
       "  {'id': 4,\n",
       "   'word': '▁is',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -0.0713052749633789},\n",
       "  {'id': 4,\n",
       "   'word': '▁is',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -4.4654082436129325},\n",
       "  {'id': 4,\n",
       "   'word': '▁are',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -8.185529708862305},\n",
       "  {'id': 4,\n",
       "   'word': '▁are',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -7.811179161071777},\n",
       "  {'id': 4,\n",
       "   'word': '▁are',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -5.2030071867437115},\n",
       "  {'id': 4,\n",
       "   'word': '▁was',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -8.65849494934082},\n",
       "  {'id': 4,\n",
       "   'word': '▁was',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -3.011469841003418},\n",
       "  {'id': 4,\n",
       "   'word': '▁was',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -4.9733395093525585},\n",
       "  {'id': 4,\n",
       "   'word': '▁this',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -10.06235122680664},\n",
       "  {'id': 4,\n",
       "   'word': '▁this',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -4.273064613342285},\n",
       "  {'id': 4,\n",
       "   'word': '▁this',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -5.065619602429015},\n",
       "  {'id': 4,\n",
       "   'word': '▁not',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -10.45890998840332},\n",
       "  {'id': 4,\n",
       "   'word': '▁not',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -9.598492622375488},\n",
       "  {'id': 4,\n",
       "   'word': '▁not',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -5.272649619799459},\n",
       "  {'id': 5,\n",
       "   'word': 'a',\n",
       "   'src': 'original',\n",
       "   'model': 'smallContext',\n",
       "   'score': -0.00033664703369140625},\n",
       "  {'id': 5,\n",
       "   'word': 'a',\n",
       "   'src': 'original',\n",
       "   'model': 'bigContext',\n",
       "   'score': -0.3533201217651367},\n",
       "  {'id': 5,\n",
       "   'word': 'a',\n",
       "   'src': 'original',\n",
       "   'model': 'noContext',\n",
       "   'score': -3.776618368421943},\n",
       "  {'id': 5,\n",
       "   'word': '▁a',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -0.00033664703369140625},\n",
       "  {'id': 5,\n",
       "   'word': '▁a',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -0.3533201217651367},\n",
       "  {'id': 5,\n",
       "   'word': '▁a',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -3.776618368421943},\n",
       "  {'id': 5,\n",
       "   'word': '▁another',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -9.381203651428223},\n",
       "  {'id': 5,\n",
       "   'word': '▁another',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -3.184300422668457},\n",
       "  {'id': 5,\n",
       "   'word': '▁another',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -7.505592279737757},\n",
       "  {'id': 5,\n",
       "   'word': '▁the',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -9.827086448669434},\n",
       "  {'id': 5,\n",
       "   'word': '▁the',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -1.7306804656982422},\n",
       "  {'id': 5,\n",
       "   'word': '▁the',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -2.831914188324596},\n",
       "  {'id': 5,\n",
       "   'word': '▁this',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -10.313738822937012},\n",
       "  {'id': 5,\n",
       "   'word': '▁this',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -7.817221641540527},\n",
       "  {'id': 5,\n",
       "   'word': '▁this',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -5.065619602429015},\n",
       "  {'id': 5,\n",
       "   'word': '▁an',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -10.790282249450684},\n",
       "  {'id': 5,\n",
       "   'word': '▁an',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -8.342083930969238},\n",
       "  {'id': 5,\n",
       "   'word': '▁an',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -5.640807675494813},\n",
       "  {'id': 6,\n",
       "   'word': 'test.',\n",
       "   'src': 'original',\n",
       "   'model': 'smallContext',\n",
       "   'score': -0.05527687072753906},\n",
       "  {'id': 6,\n",
       "   'word': 'test.',\n",
       "   'src': 'original',\n",
       "   'model': 'bigContext',\n",
       "   'score': -18.980817317962646},\n",
       "  {'id': 6,\n",
       "   'word': 'test.',\n",
       "   'src': 'original',\n",
       "   'model': 'noContext',\n",
       "   'score': -8.752915524937308},\n",
       "  {'id': 6,\n",
       "   'word': '.',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -0.04869556427001953},\n",
       "  {'id': 6,\n",
       "   'word': '.',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -6.471547603607178},\n",
       "  {'id': 6,\n",
       "   'word': '.',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 6,\n",
       "   'word': ',',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -5.214212417602539},\n",
       "  {'id': 6,\n",
       "   'word': ',',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -5.6935343742370605},\n",
       "  {'id': 6,\n",
       "   'word': ',',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 6,\n",
       "   'word': '?',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -6.366283416748047},\n",
       "  {'id': 6,\n",
       "   'word': '?',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -8.639260292053223},\n",
       "  {'id': 6,\n",
       "   'word': '?',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -1},\n",
       "  {'id': 6,\n",
       "   'word': '▁for',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -6.490809440612793},\n",
       "  {'id': 6,\n",
       "   'word': '▁for',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -4.718697547912598},\n",
       "  {'id': 6,\n",
       "   'word': '▁for',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -4.585367558691911},\n",
       "  {'id': 6,\n",
       "   'word': '▁Guangzhou',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'smallContext',\n",
       "   'score': -6.816531181335449},\n",
       "  {'id': 6,\n",
       "   'word': '▁Guangzhou',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'bigContext',\n",
       "   'score': -8.739112854003906},\n",
       "  {'id': 6,\n",
       "   'word': '▁Guangzhou',\n",
       "   'src': 'smallContext',\n",
       "   'model': 'noContext',\n",
       "   'score': -13.168407315905736}],\n",
       " ['bigContext', 'smallContext', 'noContext'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_scores(\"Hello. This is a test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2020",
   "language": "python",
   "name": "summer2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
