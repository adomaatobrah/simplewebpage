{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['>>fr<<', '>>es<<', '>>it<<', '>>pt<<', '>>pt_br<<', '>>ro<<', '>>ca<<', '>>gl<<', '>>pt_BR<<', '>>la<<', '>>wa<<', '>>fur<<', '>>oc<<', '>>fr_CA<<', '>>sc<<', '>>es_ES<<', '>>es_MX<<', '>>es_AR<<', '>>es_PR<<', '>>es_UY<<', '>>es_CL<<', '>>es_CO<<', '>>es_CR<<', '>>es_GT<<', '>>es_HN<<', '>>es_NI<<', '>>es_PA<<', '>>es_PE<<', '>>es_VE<<', '>>es_DO<<', '>>es_EC<<', '>>es_SV<<', '>>an<<', '>>pt_PT<<', '>>frp<<', '>>lad<<', '>>vec<<', '>>fr_FR<<', '>>co<<', '>>it_IT<<', '>>lld<<', '>>lij<<', '>>lmo<<', '>>nap<<', '>>rm<<', '>>scn<<', '>>mwl<<']\n"
    }
   ],
   "source": [
    "en_ROMANCE_model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'\n",
    "en_ROMANCE_tokenizer = MarianTokenizer.from_pretrained(en_ROMANCE_model_name)\n",
    "print(en_ROMANCE_tokenizer.supported_language_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_ROMANCE = MarianMTModel.from_pretrained(en_ROMANCE_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROMANCE_en_model_name = 'Helsinki-NLP/opus-mt-ROMANCE-en'\n",
    "ROMANCE_en_tokenizer = MarianTokenizer.from_pretrained(ROMANCE_en_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROMANCE_en = MarianMTModel.from_pretrained(ROMANCE_en_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'transpose'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-34a4a4760110>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     )\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mnext_token_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_outputs, decoder_input_ids, decoder_attention_mask, decoder_cached_states, lm_labels, use_cache, **unused)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    957\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, encoder_outputs, decoder_attention_mask, decoder_cached_states, use_cache)\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0mdecoder_causal_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m             \u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m         )\n\u001b[0;32m    848\u001b[0m         \u001b[1;31m# Attention and hidden_states will be [] or None if they aren't needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, encoder_hidden_states, encoder_padding_mask, decoder_padding_mask, decoder_causal_mask, decoder_cached_states, use_cache, **unused)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;31m# Convert to Bart output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         \u001b[0mencoder_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# decoder layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "skip = \"true\"\n",
    "english = \"It was a dark and stormy night\"\n",
    "start = \"The\"\n",
    "\n",
    "#english only- spanish behind the scenes\n",
    "if skip == \"true\":\n",
    "    tokenizer = ROMANCE_en_tokenizer\n",
    "    model = ROMANCE_en\n",
    "\n",
    "#show spanish\n",
    "else:\n",
    "    tokenizer = en_ROMANCE_tokenizer\n",
    "    model = en_ROMANCE\n",
    "\n",
    "starting_word = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(start))\n",
    "prefix = torch.LongTensor(starting_word)\n",
    "\n",
    "batch = tokenizer.prepare_translation_batch([\">>es<<\" + english])\n",
    "english_encoded = model.get_encoder()(**batch)\n",
    "decoder_start_token = model.config.decoder_start_token_id\n",
    "# pylint: disable=E1101\n",
    "partial_decode = torch.LongTensor([decoder_start_token]).unsqueeze(0)\n",
    "past = (english_encoded, None)\n",
    "# pylint: enable=E1101\n",
    "\n",
    "num_tokens_generated = 0\n",
    "\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "prediction_list = []\n",
    "total = 0\n",
    "#stop when </s> token generated, or max num tokens exceded (just in case)\n",
    "while True:#next_token_to_add.item() != 0 and x < MAX_LENGTH:\n",
    "    model_inputs = model.prepare_inputs_for_generation(\n",
    "    partial_decode, past=past, attention_mask=batch['attention_mask'], use_cache=model.config.use_cache\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model_outputs = model(**model_inputs)\n",
    "\n",
    "    next_token_logits = model_outputs[0][0, -1, :]\n",
    "    past = model_outputs[1]\n",
    "\n",
    "    #start with user inputted beginning\n",
    "    if x < len(prefix):\n",
    "        next_token_to_add = prefix[x]\n",
    "    else:\n",
    "        next_token_to_add = next_token_logits[0].topk(100).indices[1].item()\n",
    "    \n",
    "    next_token_logprobs = next_token_logits - next_token_logits.logsumexp()\n",
    "    score = next_token_logprobs[next_token_to_add].item()\n",
    "    total += score\n",
    "    \n",
    "    #     P(this is cool) =       P(this) * P(is | this) * P(cool | this is)\n",
    "    # log P(this is cool) = log ( P(this) * P(is | this) * P(cool | this is) )\n",
    "    #                     = log P(this) + log P(is | this) + log P(cool | this is)\n",
    "    \n",
    "    # score_A = -5     exp(score_A) <- positive\n",
    "    # score_B = 2      exp(score_B)\n",
    "    # \n",
    "    #     P(A) = exp(score_A) / ( exp(score_A) + exp(score_B) )\n",
    "    # log P(A) = score_A - log ( exp(score_A) + exp(score_B) ) )\n",
    "        \n",
    "    #append top 10 predictions for each token to list\n",
    "    decoded_predictions = []\n",
    "    for tok in next_token_logits[0].topk(10).indices:\n",
    "        decoded_predictions.append(tokenizer.convert_ids_to_tokens(tok.item()).replace('\\u2581', '\\u00a0'))\n",
    "\n",
    "    #list of lists of predictions\n",
    "    prediction_list.append(decoded_predictions)\n",
    "\n",
    "    #add new token to tokens so far\n",
    "    partial_decode = torch.cat((partial_decode, next_token_to_add.unsqueeze(0).unsqueeze(0)), -1)\n",
    "    x += 1\n",
    "    \n",
    "    if next_token_to_add.item() == 0 or not (num_tokens_generated < MAX_LEN):\n",
    "        break\n",
    "\n",
    "#list of tokens used to display sentence\n",
    "decoded_tokens = [sub.replace('\\u2581', '\\u00a0') for sub in tokenizer.convert_ids_to_tokens(partial_decode[0])]\n",
    "decoded_tokens.remove(\"<pad>\")\n",
    "\n",
    "final = tokenizer.decode(partial_decode[0]).replace(\"<pad>\", '')\n",
    "print(final)\n",
    "total/len(decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'next_token_logits' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-cf455b568fe3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext_token_logits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'next_token_logits' is not defined"
     ]
    }
   ],
   "source": [
    "next_token_logits.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits[next_token_logits.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([-4.0181, -0.0181])"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "logits = torch.Tensor([-2., 2.]) - 2.0181\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0.0180, 0.9821])"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "unnormalized_probs = logits.exp() \n",
    "unnormalized_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = unnormalized_probs / unnormalized_probs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([-4.0181, -0.0181])"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "logprobs = probs.log()\n",
    "logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'log' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-b9b832e1f045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogits\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'log' is not defined"
     ]
    }
   ],
   "source": [
    "logits - log(sum(exp(logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(4.9938e-05)"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "logits.logsumexp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "'' was not found in history, as a file, url, nor in the user namespace.\n"
    }
   ],
   "source": [
    "save[0].topk(11).indices[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'next_token_logits' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-5f4a51d23242>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext_token_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'next_token_logits' is not defined"
     ]
    }
   ],
   "source": [
    "next_token_logits[0].topk(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'next_token_logits' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-df6f3fc4084a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext_token_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'next_token_logits' is not defined"
     ]
    }
   ],
   "source": [
    "next_token_logits[0].topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'next_token_logits' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-d0d539d75be4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext_token_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'next_token_logits' is not defined"
     ]
    }
   ],
   "source": [
    "next_token_logits[0].topk(11).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['▁The']"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'decoded_tokens' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-55f959b26e18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecoded_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'decoded_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "decoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[65000]])\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'transpose'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-13d5dd2f8763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     )\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mnext_token_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_outputs, decoder_input_ids, decoder_attention_mask, decoder_cached_states, lm_labels, use_cache, **unused)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    957\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, encoder_outputs, decoder_attention_mask, decoder_cached_states, use_cache)\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0mdecoder_causal_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m             \u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m         )\n\u001b[0;32m    848\u001b[0m         \u001b[1;31m# Attention and hidden_states will be [] or None if they aren't needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, encoder_hidden_states, encoder_padding_mask, decoder_padding_mask, decoder_causal_mask, decoder_cached_states, use_cache, **unused)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;31m# Convert to Bart output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         \u001b[0mencoder_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# decoder layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = en_ROMANCE_tokenizer\n",
    "model = en_ROMANCE\n",
    "#tokenizer = ROMANCE_en_tokenizer\n",
    "#model = ROMANCE_en\n",
    "\n",
    "\n",
    "english = \">>es<<It was a dark and stormy night\"\n",
    "batch = tokenizer.prepare_translation_batch([english])\n",
    "english_encoded = model.get_encoder()(**batch)\n",
    "decoder_start_token = model.config.decoder_start_token_id\n",
    "\n",
    "starting_word = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"La\"))\n",
    "#starting_word = tokenizer.encode(\"A la\")\n",
    "\n",
    "partial_decode = torch.LongTensor([decoder_start_token]).unsqueeze(0)\n",
    "past = (english_encoded, None)\n",
    "\n",
    "prefix = torch.LongTensor(starting_word)\n",
    "#prefix = torch.LongTensor(tokenizer.convert_tokens_to_ids(\"A la\".replace(' ', '▁').split('▁')))\n",
    "#prefix = torch.LongTensor(tokenizer.encode(\"A la\"))\n",
    "#prefix = torch.LongTensor(tokenizer.encode(\"A▁la▁\"))\n",
    "next_token_to_add = torch.tensor(1)\n",
    "x = 0\n",
    "\n",
    "prediction_list = []\n",
    "\n",
    "while next_token_to_add.item() != 0 and x < 100:\n",
    "    print(partial_decode)\n",
    "    model_inputs = model.prepare_inputs_for_generation(\n",
    "    partial_decode, past=past, attention_mask=batch['attention_mask'], use_cache=model.config.use_cache\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model_outputs = model(**model_inputs)\n",
    "\n",
    "    next_token_logits = model_outputs[0][:, -1, :]\n",
    "    past = model_outputs[1]\n",
    "    \n",
    "    if x < len(prefix):\n",
    "        next_token_to_add = prefix[x]\n",
    "        print(x, \": \", next_token_to_add)\n",
    "    else:\n",
    "        next_token_to_add = next_token_logits[0].argmax()\n",
    "\n",
    "    decoded_predictions = []\n",
    "    for tok in next_token_logits[0].topk(5).indices:\n",
    "        decoded_predictions.append(tokenizer.convert_ids_to_tokens(tok.item()).replace('\\u2581', '\\u00a0'))\n",
    "    \n",
    "    prediction_list.append(decoded_predictions)\n",
    "    \n",
    "    partial_decode = torch.cat((partial_decode, next_token_to_add.unsqueeze(0).unsqueeze(0)), -1)\n",
    "    x += 1\n",
    "    \n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(partial_decode[0])\n",
    "\n",
    "decoded_tokens = [sub.replace('\\u2581', '\\u00a0') for sub in tokenizer.convert_ids_to_tokens(partial_decode[0])] \n",
    "\n",
    "final = tokenizer.decode(partial_decode[0]).split(\"<pad>\")[1]\n",
    "print(final)\n",
    "print(decoded_tokens)\n",
    "print(prediction_list)\n",
    "\n",
    "batch2 = ROMANCE_en_tokenizer.prepare_translation_batch([\">>en<< \" + final])\n",
    "spanish_to_english = ROMANCE_en.generate(**batch2)\n",
    "new_english = ROMANCE_en_tokenizer.decode(spanish_to_english[0]).split(\"<pad>\")[1]\n",
    "\n",
    "new_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'transpose'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-c532c746fb5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         )\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mnext_token_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mpast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_outputs, decoder_input_ids, decoder_attention_mask, decoder_cached_states, lm_labels, use_cache, **unused)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    957\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, encoder_outputs, decoder_attention_mask, decoder_cached_states, use_cache)\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0mdecoder_causal_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m             \u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m         )\n\u001b[0;32m    848\u001b[0m         \u001b[1;31m# Attention and hidden_states will be [] or None if they aren't needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, encoder_hidden_states, encoder_padding_mask, decoder_padding_mask, decoder_causal_mask, decoder_cached_states, use_cache, **unused)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;31m# Convert to Bart output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         \u001b[0mencoder_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# decoder layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "tokenizer = en_ROMANCE_tokenizer\n",
    "model = en_ROMANCE\n",
    "\n",
    "english = \">>es<<It was a dark and stormy night\"\n",
    "batch = tokenizer.prepare_translation_batch([english])\n",
    "english_encoded = model.get_encoder()(**batch)\n",
    "decoder_start_token = model.config.decoder_start_token_id\n",
    "\n",
    "starting_word = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"\"))\n",
    "prefix = torch.LongTensor(starting_word)\n",
    "prediction_list = []\n",
    "alternatives = []\n",
    "for x in range(0, 5):\n",
    "\n",
    "    past = (english_encoded, None)\n",
    "   \n",
    "    partial_decode = torch.LongTensor([decoder_start_token]).unsqueeze(0)\n",
    "    y = 0\n",
    "    next_token_to_add = torch.tensor(1)\n",
    "    while next_token_to_add.item() != 0 and y < 100:    \n",
    "        model_inputs = model.prepare_inputs_for_generation(\n",
    "        partial_decode, past=past, attention_mask=batch['attention_mask'], use_cache=model.config.use_cache\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model(**model_inputs)\n",
    "        next_token_logits = model_outputs[0][:, -1, :]\n",
    "        past = model_outputs[1]\n",
    "\n",
    "        if y < len(prefix):\n",
    "            next_token_to_add = prefix[y]\n",
    "        else:\n",
    "            next_token_to_add = next_token_logits[0].topk(4).indices[random.randint(0, 1)]\n",
    "        decoded_predictions = []\n",
    "        for tok in next_token_logits[0].topk(5).indices:\n",
    "            decoded_predictions.append(tokenizer.convert_ids_to_tokens(tok.item()).replace('\\u2581', '\\u00a0'))\n",
    "\n",
    "        prediction_list.append(decoded_predictions)\n",
    "        partial_decode = torch.cat((partial_decode, next_token_to_add.unsqueeze(0).unsqueeze(0)), -1)\n",
    "        y += 1\n",
    "\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(partial_decode[0])\n",
    "\n",
    "    final = tokenizer.decode(partial_decode[0]).split(\"<pad>\")[1]\n",
    "    print(final)\n",
    "    alternatives.append(final)\n",
    "    \n",
    "alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'decoded_tokens' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-55f959b26e18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecoded_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'decoded_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "decoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[' Creo que esta es la tienda equivocada.',\n ' Creo que tal vez esta es la tienda equivocada.',\n ' Creo que quizás esta es la tienda equivocada.',\n ' Creo que puede que esta sea la tienda equivocada.',\n ' Creo que esta tal vez es la tienda equivocada.',\n ' Creo que quizá esta es la tienda equivocada.',\n ' Creo que ésta es la tienda equivocada.',\n ' Creo que es la tienda equivocada.',\n ' Creo que esta puede ser la tienda equivocada.',\n ' Creo que quizá esta sea la tienda equivocada.',\n ' Creo que quizás esta sea la tienda equivocada.',\n ' Creo que tal vez esta sea la tienda equivocada.',\n ' Pienso que esta es la tienda equivocada.',\n ' Creo que a lo mejor esta es la tienda equivocada.',\n ' Creo que puede que esta es la tienda equivocada.',\n ' Creo que tal vez ésta es la tienda equivocada.',\n ' Creo que esta es una tienda equivocada.',\n ' Creo que puede que ésta sea la tienda equivocada.',\n ' Creo que esto es la tienda equivocada.',\n ' Creo que esta tal vez sea la tienda equivocada.',\n ' Creo que tal vez es la tienda equivocada.',\n ' Creo que quizás ésta es la tienda equivocada.',\n ' Creo que esa es la tienda equivocada.',\n ' Creo que esta es la tienda incorrecta.',\n ' Creo que esta es la tienda errónea.',\n ' Creo que quizá ésta es la tienda equivocada.',\n ' Creo que puede ser la tienda equivocada.',\n ' Creo que esta es quizás la tienda equivocada.',\n ' Creo que quizás es la tienda equivocada.',\n ' Creo que tal vez esta es la tienda incorrecta.',\n ' Creo que quizá es la tienda equivocada.',\n ' Creo que está es la tienda equivocada.',\n ' Creo que esta no es la tienda correcta.',\n ' Quizá esta sea la tienda equivocada.',\n ' Creo que tal vez esta es la tienda errónea.',\n ' Creo que esta tal vez no es la tienda correcta.',\n ' Quizá esta es la tienda equivocada.',\n ' Creo que es una tienda equivocada.',\n ' Creo que esta es la tienda equivocada',\n ' Creo que esta tal vez es la tienda incorrecta.',\n ' Creo que puede que esta sea la tienda incorrecta.',\n ' Creo que quizás esta es la tienda incorrecta.',\n ' Creo que esta no es la tienda.',\n ' Creo que tal vez esta tienda no es la correcta.',\n ' Creo que esta tal vez no es la tienda.',\n ' Creo que quizá esta es la tienda incorrecta.',\n ' Creo que tal vez esta es la tienda equivocada',\n ' Creo que esta se equivoca de tienda.',\n ' Creo que esta es la tienda equivocada, tal vez.',\n ' Creo que quizás esta tienda no es la correcta.']"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "tokenizer = en_ROMANCE_tokenizer\n",
    "model = en_ROMANCE\n",
    "\n",
    "english = \">>es<<I think maybe this is the wrong store.\"\n",
    "batch = tokenizer.prepare_translation_batch([english])\n",
    "                                            \n",
    "eng_to_spanish = model.generate(num_beams=50, num_return_sequences=50, **batch)\n",
    "\n",
    "translations = []\n",
    "for x in range(0, 50):\n",
    "    translations.append(tokenizer.decode(eng_to_spanish[x]).split(\"<pad>\")[1])\n",
    "\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([65000,    23,    20,   391,   260,   844,    63,    26,     4,  2101,\n         5951,     3])"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "back_to_english[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'<pad> - I think maybe this is the wrong store.'"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "ROMANCE_en_tokenizer.decode(back_to_english[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'>>en<<( etp▁States doit are des the▁greater leadership.'"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "\">>en<<\" + tokenizer.decode(spanish[0]).replace(\"<pad> \", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([65000,    23,    20,   391,   260,   844,    63,    26,     4,  2101,\n         5951,     3])"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "back_to_english[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"<pad>You're my best friend.<pad><pad><pad><pad><pad><pad><pad><pad>\""
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "ROMANCE_en_tokenizer.decode([65000,   4932,    7,    66,   148,   660,  2203,     3,     0, 65000,\n",
    "        65000, 65000, 65000, 65000, 65000, 65000, 65000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([65000,   111,    57,   148,  7112,  9036,     0, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,   111,     7,    66,   148,  7112,  9036,     3,     0, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,   111,    57,   148,  7112,  9036,     3,     0, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,   111,     7,    66,   148,  7112,  9036,     0, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,   111,     7,    66,   148,  7112,  9036,     3,   111,     7,\n           66,   148,  7112,  9036,     3,     0])\ntensor([65000,    31,     7,    66,   148,  7112,  9036,     3,     0, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,    31,    57,   148,  7112,  9036,     0, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,    31,     7,    66,   148,  7112,  9036,     0, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,   111,     7,    66,   148,  7112,  9036,    78,   111,     7,\n           66,   148,  7112,  9036,    78,     0])\ntensor([65000,   111,     7,    66,   148,  7112, 15659,     3,     0, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,    31,     7,    66,   148,  7112,  9036,     3,   111,     7,\n           66,   148,  7112,  9036,     3,     0])\ntensor([65000,   111,   187,     2,    31,     7,    66,   148,  7112,  9036,\n            3,     0, 65000, 65000, 65000, 65000])\ntensor([65000,   111,     7,    66,   148,  7112,  9036,     3,   111,    57,\n          148,  7112,  9036,     3,     0, 65000])\ntensor([65000,   111,     7,    66,   148,  7112,  9036,     2,    31,     7,\n           66,   148,  7112,  9036,     3,     0])\ntensor([65000,   111,     7,    66,   148,  7112, 15659,     3,   111,     7,\n           66,   148,  7112, 15659,     3,     0])\ntensor([65000,   111,     7,    66,   148,  7112,  9036,    78,     0, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,    31,    57,   148,  7112,  9036,     3,     0, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\ntensor([65000,   111,     7,    66,   148,  7112,  9036,     3,   111,     7,\n           66,   148,  7112, 15659,     3,     0])\ntensor([65000,   111,     7,    66,   148,  7112,  9036,     3,   111,     7,\n           66,   148,  7112,  9036,    78,     0])\ntensor([65000,   111,    57,   148,  7112, 15659,     3,     0, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[' You are my soul mate',\n \" You're my soul mate.\",\n ' You are my soul mate.',\n \" You're my soul mate\",\n \" You're my soul mate. You're my soul mate.\",\n \" you're my soul mate.\",\n ' you are my soul mate',\n \" you're my soul mate\",\n \" You're my soul mate! You're my soul mate!\",\n \" You're my soulmate.\",\n \" you're my soul mate. You're my soul mate.\",\n \" You know, you're my soul mate.\",\n \" You're my soul mate. You are my soul mate.\",\n \" You're my soul mate, you're my soul mate.\",\n \" You're my soulmate. You're my soulmate.\",\n \" You're my soul mate!\",\n ' you are my soul mate.',\n \" You're my soul mate. You're my soulmate.\",\n \" You're my soul mate. You're my soul mate!\",\n ' You are my soulmate.']"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "tokenizer = en_ROMANCE_tokenizer\n",
    "model = en_ROMANCE\n",
    "\n",
    "english = \">>es<<You're my soulmate\"\n",
    "batch = tokenizer.prepare_translation_batch([english])\n",
    "\n",
    "spanish = model.generate(**batch)\n",
    "\n",
    "batch2 = ROMANCE_en_tokenizer.prepare_translation_batch([\">>en<<\" + tokenizer.decode(spanish[0])])\n",
    "\n",
    "back_to_english = ROMANCE_en.generate(num_beams=20, num_return_sequences=20, bad_words_ids=[[1695],[1973],[7927],[55],[23],[367],[51],[12390],[1172],[45351],[39]], **batch2)\n",
    "\n",
    "translations = []\n",
    "for x in range(0, 20):\n",
    "    print(back_to_english[x])\n",
    "    translations.append(ROMANCE_en_tokenizer.decode(back_to_english[x]).replace(\"<pad>\", ''))\n",
    "    \n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[23, 0], [51, 0]]"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "bad_words_ids = [ROMANCE_en_tokenizer.encode(bad_word) for bad_word in ['-', '\"']]\n",
    "bad_words_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['</s>']"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "ROMANCE_en_tokenizer.convert_ids_to_tokens([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "47075"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "ROMANCE_en_tokenizer.convert_tokens_to_ids('♪')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'transpose'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-cebb2e51efd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     )\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mROMANCE_en\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mnext_token_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_outputs, decoder_input_ids, decoder_attention_mask, decoder_cached_states, lm_labels, use_cache, **unused)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    957\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, encoder_outputs, decoder_attention_mask, decoder_cached_states, use_cache)\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0mdecoder_causal_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m             \u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_cached_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m         )\n\u001b[0;32m    848\u001b[0m         \u001b[1;31m# Attention and hidden_states will be [] or None if they aren't needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, encoder_hidden_states, encoder_padding_mask, decoder_padding_mask, decoder_causal_mask, decoder_cached_states, use_cache, **unused)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;31m# Convert to Bart output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         \u001b[0mencoder_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# decoder layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "english = \">>es<<I think maybe this is the wrong store.\"\n",
    "batch = tokenizer.prepare_translation_batch([english])\n",
    "                                            \n",
    "spanish = model.generate(**batch)\n",
    "\n",
    "batch = ROMANCE_en_tokenizer.prepare_translation_batch([\">>en<<\" + tokenizer.decode(spanish[0]).replace(\"<pad>\", '')])\n",
    "back_to_english = ROMANCE_en.generate(**batch)\n",
    "machine_translation = ROMANCE_en_tokenizer.decode(back_to_english[0]).replace(\"<pad>\", '')\n",
    "\n",
    "spanish_encoded = ROMANCE_en.get_encoder()(**batch)\n",
    "decoder_start_token = ROMANCE_en.config.decoder_start_token_id\n",
    "# pylint: disable=E1101\n",
    "partial_decode = torch.LongTensor([decoder_start_token]).unsqueeze(0)\n",
    "past = (spanish_encoded, None)\n",
    "# pylint: enable=E1101\n",
    "next_token_to_add = torch.tensor(1)\n",
    "x = 0\n",
    "\n",
    "prediction_list = []\n",
    "\n",
    "while next_token_to_add.item() != 0 and x < 100:\n",
    "    model_inputs = ROMANCE_en.prepare_inputs_for_generation(\n",
    "    partial_decode, past=past, attention_mask=batch['attention_mask'], use_cache=ROMANCE_en.config.use_cache\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model_outputs = ROMANCE_en(**model_inputs)\n",
    "\n",
    "    next_token_logits = model_outputs[0][:, -1, :]\n",
    "    past = model_outputs[1]\n",
    "   \n",
    "    if x == 3:\n",
    "        next_token_to_add = next_token_logits[0].topk(4).indices[1]\n",
    "    else:\n",
    "        next_token_to_add= next_token_logits[0].argmax()\n",
    "    decoded_predictions = []\n",
    "    for tok in next_token_logits[0].topk(10).indices:\n",
    "        decoded_predictions.append(ROMANCE_en_tokenizer.convert_ids_to_tokens(tok.item()).replace('\\u2581', '\\u00a0'))\n",
    "\n",
    "    prediction_list.append(decoded_predictions)\n",
    "\n",
    "    partial_decode = torch.cat((partial_decode, next_token_to_add.unsqueeze(0).unsqueeze(0)), -1)\n",
    "    x+= 1\n",
    "\n",
    "decoded_tokens = [sub.replace('\\u2581', '\\u00a0') for sub in ROMANCE_en_tokenizer.convert_ids_to_tokens(partial_decode[0])]\n",
    "decoded_tokens.remove(\"<pad>\")\n",
    "final = ROMANCE_en_tokenizer.decode(partial_decode[0]).split(\"<pad>\")[1]\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "' - I think maybe this is the wrong store.'"
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "machine_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "1;33m\n\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"`repetition_penalty` should be >= 1.\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbos_token_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbos_token_id\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"If input_ids is not defined, `bos_token_id` should be a positive integer.\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[0mpad_token_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"`pad_token_id` should be a positive integer.\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meos_token_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meos_token_id\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"`eos_token_id` should be a positive integer.\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[0mlength_penalty\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"`length_penalty` should be strictly positive.\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_repeat_ngram_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_repeat_ngram_size\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"`no_repeat_ngram_size` should be a positive integer.\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnum_return_sequences\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"`num_return_sequences` should be a strictly positive integer.\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mbad_words_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_words_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_words_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"`bad_words_ids` is either `None` or a list of lists of tokens that should not be generated\"\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbos_token_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbos_token_id\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;34m\"you should either supply a context to complete as `input_ids` input \"\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;34m\"or a `bos_token_id` (integer >= 0) as a first token to start the generation.\"\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbos_token_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32massert\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Input prompt should be of shape (batch_size, sequence length).\"\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;31m# not allow to duplicate outputs when greedy decoding\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mdo_sample\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;31m# no_beam_search greedy generation conditions\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                    \u001b[0mnum_return_sequences\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Greedy decoding will always produce the same output for num_beams == 1 and num_return_sequences > 1. Please set num_return_sequences = 1\"\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;31m# beam_search greedy generation conditions\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                    \u001b[0mnum_beams\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Greedy beam search decoding cannot return more sequences than it has beams. Please set num_beams >= num_return_sequences\"\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;31m# create attention mask if necessary\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;31m# TODO (PVP): this should later be handled by the forward fn() in each model in the future see PR 3140\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattention_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mattention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mattention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;31m# set pad_token_id to eos_token_id if not set. Important that this is done after\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;31m# attention_mask is created\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mpad_token_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0meos_token_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;34m\"Setting `pad_token_id` to {} (first `eos_token_id`) to generate sequence\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mpad_token_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;31m# current position and vocab size\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"vocab_size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"decoder\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"vocab_size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;31m# set effective batch size and effective batch multiplier according to do_sample\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0meffective_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0meffective_batch_mult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0meffective_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0meffective_batch_mult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mdecoder_start_token_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mdecoder_start_token_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbos_token_id\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mdecoder_start_token_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"decoder_start_token_id or bos_token_id has to be defined for encoder-decoder generation\"\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"get_encoder\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"{} should have a 'get_encoder' function defined\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"{} should be a method\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;31m# get encoder and store encoder outputs\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;31m# Expand input ids if num_beams > 1 or num_return_sequences > 1\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mnum_return_sequences\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0minput_ids_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meffective_batch_mult\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mattention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meffective_batch_mult\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids_len\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0meffective_batch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids_len\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m  \u001b[1;31m# shape: (batch_size * num_return_sequences * num_beams, cur_len)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mattention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0meffective_batch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids_len\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m  \u001b[1;31m# shape: (batch_size * num_return_sequences * num_beams, cur_len)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;31m# create empty decoder_input_ids\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;33m(\u001b[0m\u001b[0meffective_batch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mdecoder_start_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mcur_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mbatch_size\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"expected encoder_outputs[0] to have 1st dimension bs={batch_size}, got {encoder_outputs[0].shape[0]} \"\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;31m# expand batch_idx to assign correct encoder output for expanded input_ids (due to num_beams > 1 and num_return_sequences > 1)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mexpanded_batch_idxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0meffective_batch_mult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;31m# expand encoder_outputs\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mencoder_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_batch_idxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mencoder_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mcur_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_beam_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mcur_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mdo_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdo_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mearly_stopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mtop_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mrepetition_penalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrepetition_penalty\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mno_repeat_ngram_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_repeat_ngram_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mbad_words_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_words_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mbos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbos_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mpad_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mdecoder_start_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_start_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0meos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meffective_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mlength_penalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlength_penalty\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mmodel_specific_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_specific_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_no_beam_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mcur_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mdo_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdo_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mtop_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mrepetition_penalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrepetition_penalty\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mno_repeat_ngram_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_repeat_ngram_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mbad_words_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_words_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mbos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbos_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mpad_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mdecoder_start_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_start_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0meos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meffective_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mmodel_specific_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_specific_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;31mFile:\u001b[0m      c:\\users\\hyech\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\n\u001b[1;31mType:\u001b[0m      method\n"
    }
   ],
   "source": [
    "model.generate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'next_token_logits' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-6ae62c6bf08c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext_token_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'next_token_logits' is not defined"
     ]
    }
   ],
   "source": [
    "next_token_logits[0].topk(3).indices[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}