{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config, AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blumen', 'und', 'Sterne', 'sind', 'erstaunlich.']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs1[0]).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(prediction_scores[0][0].topk(4).indices).split(' ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    3, 28240,    14,    14,    14,    14,    14,    14,    14])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(64)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_scores[0][2].topk(4).indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "    english = \"When Liana Barrientos was 23 years old, she got married in Westchester County.\"\n",
    "    german = \"Liana fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill\"\n",
    "\n",
    "    #encode english input with prefix\n",
    "    input_ids = tokenizer.encode(\"translate English to German: \" + english, return_tensors=\"pt\")\n",
    "    \n",
    "    output_ids = tokenizer.encode(german, return_tensors='pt')\n",
    "\n",
    "    for x in range (1, 22):\n",
    "        outputs = model(input_ids=input_ids, lm_labels=output_ids)\n",
    "\n",
    "        loss, prediction_scores = outputs[:2]\n",
    "\n",
    "        second_choice = prediction_scores[0][x].topk(1).indices[0]\n",
    "        output_ids[0][x] = second_choice\n",
    "\n",
    "    final = tokenizer.decode(output_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sie x x x x x x x x x x x\n",
      "Sie läuft x x x x x x x x x x\n",
      "Sie läuft langsamx x x x x x x x x x\n",
      "Sie läuft langsam und x x x x x x x x x\n",
      "Sie läuft langsam und x x x x x x x x x\n",
      "Sie läuft langsam und ich x x x x x x x x\n",
      "Sie läuft langsam und ich springx x x x x x x x\n",
      "Sie läuft langsam und ich springe x x x x x x x\n",
      "Sie läuft langsam und ich springe schnellx x x x x x x\n",
      "Sie läuft langsam und ich springe schnell. x x x x x x\n",
      "Sie läuft langsam und ich springe schnell.x x x x x x\n"
     ]
    }
   ],
   "source": [
    "english = \"I jump quickly and she runs slowly.\"\n",
    "german = \"Sie x x x x x x x x x x x\"\n",
    "\n",
    "input_ids = tokenizer.encode(\"translate English to German: \" + english, return_tensors=\"pt\")\n",
    "    \n",
    "output_ids = tokenizer.encode(german, return_tensors='pt')\n",
    "\n",
    "for x in range (1, 12):\n",
    "    outputs = model(input_ids=input_ids, lm_labels=output_ids)\n",
    "\n",
    "    loss, prediction_scores = outputs[:2]\n",
    "\n",
    "    first_choice = prediction_scores[0][x].topk(1).indices[0]\n",
    "    output_ids[0][x] = first_choice\n",
    "    print(tokenizer.decode(output_ids[0]))\n",
    "\n",
    "final = tokenizer.decode(output_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  292,     3, 15241, 20194,    64,     3,   362,  2141,    15,  3942,\n",
       "             5,     1,   226,     3,   226,     3,   226,     3,   226,     3,\n",
       "           226,     3,   226]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sie läuft langsam und ich springe schnell.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(prediction_scores[0][22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-104ca9bc6d22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgerman\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0moutput_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlm_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [2]"
     ]
    }
   ],
   "source": [
    "    english = \"She jumps and I run\"\n",
    "    german = \"Ich\"\n",
    "\n",
    "    #encode english input with prefix\n",
    "    input_ids = tokenizer.encode(\"translate English to German: \" + english, return_tensors=\"pt\")\n",
    "    output_ids = tokenizer.encode(german, return_tensors='pt')\n",
    "\n",
    "    for x in range (1, 8):\n",
    "        \n",
    "        print(german)\n",
    "        output_ids[0] = torch.cat((output_ids[0], torch.tensor([5])), 0)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, lm_labels=output_ids)\n",
    "        loss, prediction_scores = outputs[:2]\n",
    "\n",
    "        second_choice = prediction_scores[0][x].topk(1).indices[0]\n",
    "        output_ids[0][x] = second_choice\n",
    "\n",
    "    german = tokenizer.decode(output_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1674,    3, 7832,   15,   64,  680, 2141,   15,   14])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1674,   14,   14,   14,   14,   14,   14,   14,   14,    5])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.cat((output_ids[0], torch.tensor([5])), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich fill fill fill fill fill fill fill fill\n",
      "Ich fill fill fill fill fill fill fill fill\n",
      "Ich fill fill fill fill fill fill fill fill\n",
      "Ich fill fill fill fill fill fill fill fill\n",
      "Ich fill fill fill fill fill fill fill fill\n",
      "Ich fill fill fill fill fill fill fill fill\n",
      "Ich fill fill fill fill fill fill fill fill\n"
     ]
    }
   ],
   "source": [
    "german = \"Ich fill fill fill fill fill fill fill fill\"\n",
    "english = \"She jumps and I run\"\n",
    "\n",
    "for x in range (1, 8):\n",
    "\n",
    "    #encode english input with prefix\n",
    "    input_ids = tokenizer.encode(\"translate English to German: \" + english, return_tensors=\"pt\")\n",
    "    output_ids = tokenizer.encode(german, return_tensors='pt')\n",
    "\n",
    "    print(german)\n",
    "    \n",
    "    outputs = model(input_ids=input_ids, lm_labels=output_ids)\n",
    "    loss, prediction_scores = outputs[:2]\n",
    "\n",
    "    second_choice = prediction_scores[0][x].topk(1).indices[0]\n",
    "    output_ids[0][x] = second_choice\n",
    "\n",
    "end = tokenizer.decode(output_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich laufe und sie springe fill'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_scores[0][1].topk(1).indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"fill\", return_tensors=\"pt\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1674,   14])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((output_ids[0], tokenizer.encode(\"fill\", return_tensors=\"pt\")[0]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich laufe und sie springe fill'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'und'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(prediction_scores[0][2].topk(4).indices).split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['translate English to German: translate English to German: When Liana Barrientos was 23 years old, she got married in Westchester County.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Als Liana Barrientos 23 Jahre alt war, heiratete sie in Westchester County.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in output_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  1985,   340,   304,    26,  1159,     7, 19450,     7,     3,\n",
       "         17265,     9, 14810,   680,    16,  1244, 13263,  1334,     6,   368,\n",
       "          1060,     5]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nach dem Tod ihres Vaters heiratete sie in Westchester County, New York.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in outputs1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-18.5946,  -8.1854, -13.3654,  ..., -40.5977, -40.6532, -40.4892],\n",
       "         [-31.9207, -13.5465, -13.5772,  ..., -45.3452, -45.3538, -45.4147],\n",
       "         [-52.3096, -25.5499, -20.8803,  ..., -65.2021, -65.0031, -65.2328],\n",
       "         ...,\n",
       "         [-46.6869, -20.4712, -18.4204,  ..., -56.4153, -56.3651, -56.2740],\n",
       "         [-33.2802, -13.0266, -12.1969,  ..., -46.4536, -46.5405, -46.4559],\n",
       "         [-38.1263, -14.5747, -16.3950,  ..., -54.0799, -54.2224, -54.2078]]],\n",
       "       grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-18.5946,  -8.1854, -13.3654,  ..., -40.5977, -40.6532, -40.4892],\n",
       "        [-31.9207, -13.5465, -13.5772,  ..., -45.3452, -45.3538, -45.4147],\n",
       "        [-52.3096, -25.5499, -20.8803,  ..., -65.2021, -65.0031, -65.2328],\n",
       "        ...,\n",
       "        [-46.6869, -20.4712, -18.4204,  ..., -56.4153, -56.3651, -56.2740],\n",
       "        [-33.2802, -13.0266, -12.1969,  ..., -46.4536, -46.5405, -46.4559],\n",
       "        [-38.1263, -14.5747, -16.3950,  ..., -54.0799, -54.2224, -54.2078]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4746,  316, 1985])\n",
      "tensor([301,  67, 680])\n",
      "tensor([13662, 21247, 23306])\n",
      "tensor([1386,  181, 1207])\n",
      "tensor([3483, 5288, 1753])\n",
      "tensor([235,  17,  32])\n",
      "tensor([   7,    3, 1902])\n",
      "tensor([1902,  256,  181])\n",
      "tensor([3861, 3093,  615])\n",
      "tensor([4445,  615, 2105])\n",
      "tensor([ 615, 1177,  229])\n",
      "tensor([  6,   3, 548])\n",
      "tensor([   3,  548, 1177])\n",
      "tensor([17265,   547, 17328])\n",
      "tensor([  9, 342, 144])\n",
      "tensor([14810,   324,    17])\n",
      "tensor([680,   3, 388])\n",
      "tensor([256,  16, 211])\n",
      "tensor([1244,   74,  340])\n",
      "tensor([13263, 20976,    18])\n",
      "tensor([1334,    5,    6])\n",
      "tensor([5, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "for word in prediction_scores[0]:\n",
    "    print(word.topk(3).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4746,  316, 1985])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_scores[0][0].topk(3).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Als', 'lime'), ['Als', 'Die', 'Nach', 'In', 'Sie']),\n",
       " (('L', 'lime'), ['L', 'die', 'sie', '', 'sich']),\n",
       " (('iana', 'lime'), ['iana', 'yana', 'illian', 'anna', 'iano']),\n",
       " (('Bar', 'lime'), ['Bar', 'mit', 'bar', '', 'schon']),\n",
       " (('rien', 'lime'), ['rien', 'rian', 'rie', 'rios', 'r']),\n",
       " (('to', 'lime'), ['to', 't', 'o', '<unk>', 's']),\n",
       " (('s', 'lime'), ['s', '', '23', 'im', 'mit']),\n",
       " (('23', 'lime'), ['23', 'im', 'mit', '23,', '22']),\n",
       " (('Jahre', 'lime'), ['Jahre', 'Jahren', 'war', 'jährige', '.']),\n",
       " (('alt', 'lime'), ['alt', 'war', 'alte', '', 'old']),\n",
       " (('war', 'lime'), ['war', 'wurde', 'ist', 'geworden', ',']),\n",
       " ((',', 'lime'), [',', '', 'ver', 'wurde', 'und']),\n",
       " (('', 'lime'), ['', 'ver', 'wurde', 'ge', 'began']),\n",
       " (('heir', 'lime'), ['heir', 'hat', 'zog', 'e', 'er']),\n",
       " (('a', 'lime'), ['a', 'ate', 'at', 'aß', 'ates']),\n",
       " (('tete', 'lime'), ['tete', 'ten', 't', 'ter', 's']),\n",
       " (('sie', 'lime'), ['sie', '', 'man', 'die', 'ihr']),\n",
       " (('in', 'yellow'), ['im', 'in', 'das', 'sich', 'die']),\n",
       " (('West', 'lime'), ['West', 'der', 'dem', 'den', 'einem']),\n",
       " (('chester', 'lime'), ['chester', 'Chester', '-', 'ham', 'er']),\n",
       " (('County', 'lime'), ['County', '.', ',', '-', 'county']),\n",
       " (('.', 'lime'), ['.', '', ',', 'und', '('])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
