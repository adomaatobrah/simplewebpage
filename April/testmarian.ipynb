{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>>fr<<', '>>es<<', '>>it<<', '>>pt<<', '>>pt_br<<', '>>ro<<', '>>ca<<', '>>gl<<', '>>pt_BR<<', '>>la<<', '>>wa<<', '>>fur<<', '>>oc<<', '>>fr_CA<<', '>>sc<<', '>>es_ES<<', '>>es_MX<<', '>>es_AR<<', '>>es_PR<<', '>>es_UY<<', '>>es_CL<<', '>>es_CO<<', '>>es_CR<<', '>>es_GT<<', '>>es_HN<<', '>>es_NI<<', '>>es_PA<<', '>>es_PE<<', '>>es_VE<<', '>>es_DO<<', '>>es_EC<<', '>>es_SV<<', '>>an<<', '>>pt_PT<<', '>>frp<<', '>>lad<<', '>>vec<<', '>>fr_FR<<', '>>co<<', '>>it_IT<<', '>>lld<<', '>>lij<<', '>>lmo<<', '>>nap<<', '>>rm<<', '>>scn<<', '>>mwl<<']\n"
     ]
    }
   ],
   "source": [
    "en_ROMANCE_model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'\n",
    "en_ROMANCE_tokenizer = MarianTokenizer.from_pretrained(en_ROMANCE_model_name)\n",
    "print(en_ROMANCE_tokenizer.supported_language_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ROMANCE = MarianMTModel.from_pretrained(en_ROMANCE_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROMANCE_en_model_name = 'Helsinki-NLP/opus-mt-ROMANCE-en'\n",
    "ROMANCE_en_tokenizer = MarianTokenizer.from_pretrained(ROMANCE_en_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROMANCE_en = MarianMTModel.from_pretrained(ROMANCE_en_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_prefix(src, prefix):\n",
    "    english = \">>es<<\" + src\n",
    "    engbatch = en_ROMANCE_tokenizer.prepare_translation_batch([english])\n",
    "    eng_to_spanish = en_ROMANCE.generate(**engbatch)\n",
    "    machine_translation = en_ROMANCE_tokenizer.decode(eng_to_spanish[0])\n",
    "\n",
    "    tokenizer = ROMANCE_en_tokenizer\n",
    "    model = ROMANCE_en\n",
    "\n",
    "    tokenized_prefix = tokenizer.convert_tokens_to_ids(en_ROMANCE_tokenizer.tokenize(prefix.strip()))\n",
    "    prefix = torch.LongTensor(tokenized_prefix)\n",
    "\n",
    "    batch = tokenizer.prepare_translation_batch([machine_translation.replace(\"<pad> \", '')])\n",
    "    english_encoded = model.get_encoder()(**batch)\n",
    "    decoder_start_token = model.config.decoder_start_token_id\n",
    "    # pylint: disable=E1101\n",
    "    partial_decode = torch.LongTensor([decoder_start_token]).unsqueeze(0)\n",
    "    past = (english_encoded, None)\n",
    "    # pylint: enable=E1101\n",
    "\n",
    "    num_tokens_generated = 0\n",
    "    total = 0\n",
    "    MAX_LENGTH = 100\n",
    "    \n",
    "    #stop when </s> token generated, or max num tokens exceded (just in case)\n",
    "    while True:\n",
    "        model_inputs = model.prepare_inputs_for_generation(\n",
    "        partial_decode, past=past, attention_mask=batch['attention_mask'], use_cache=model.config.use_cache\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model(**model_inputs)\n",
    "\n",
    "        next_token_logits = model_outputs[0][:, -1, :]\n",
    "        past = model_outputs[1]\n",
    "\n",
    "        #start with user inputted beginning\n",
    "        if num_tokens_generated < len(prefix):\n",
    "            next_token_to_add = prefix[num_tokens_generated]\n",
    "        else:\n",
    "            break\n",
    "#             next_token_to_add = next_token_logits[0].argmax()\n",
    "\n",
    "        next_token_logprobs = next_token_logits - next_token_logits.logsumexp(1, True)\n",
    "        token_score = next_token_logprobs[0][next_token_to_add].item()\n",
    "        total += token_score\n",
    "\n",
    "        #add new token to tokens so far\n",
    "        partial_decode = torch.cat((partial_decode, next_token_to_add.unsqueeze(0).unsqueeze(0)), -1)\n",
    "        num_tokens_generated+= 1\n",
    "\n",
    "        if next_token_to_add.item() == 0 or not (num_tokens_generated < MAX_LENGTH):\n",
    "            break\n",
    "\n",
    "    #list of tokens used to display sentence\n",
    "    decoded_tokens = [sub.replace('\\u2581', '\\u00a0') for sub in tokenizer.convert_ids_to_tokens(partial_decode[0])]\n",
    "    decoded_tokens.remove(\"<pad>\")\n",
    "\n",
    "    final = tokenizer.decode(partial_decode[0]).replace(\"<pad>\", '')\n",
    "    score = round(total/(len(decoded_tokens)), 3)\n",
    "\n",
    "    return (score, final.lstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.806, 'All cats')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_prefix(\"In my opinion, all cats are great.\", \"All cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-6.632, 'All of the confirming'), (-7.558, 'Famous confirming'), (-8.163, 'Confirming confirming'), (-8.461, 'Yellowstone National park was confirming'), (-8.461, 'The confirming'), (-8.461, 'The confirming'), (-8.461, 'The confirming'), (-8.477, 'Once they confirming'), (-8.629, 'Before confirming'), (-8.629, 'Before confirming'), (-8.629, 'Before confirming'), (-9.717, 'As confirming'), (-9.843, 'Once confirming'), (-9.856, 'Cats confirming'), (-9.917, 'Easter Island as long been confirming'), (-10.337, 'Yellowstone confirming'), (-10.901, 'They confirming'), (-11.055, 'Our confirming'), (-11.095, 'Those confirming'), (-11.148, 'Those charasmatic confirming'), (-11.271, 'All confirming'), (-11.806, 'Charasmatic confirming'), (-11.838, 'Our fundamental confirming'), (-11.933, 'Been confirming'), (-11.967, 'Was confirming'), (-12.033, 'Of confirming'), (-12.072, 'Easter confirming'), (-12.381, 'Values confirming'), (-12.402, 'National confirming'), (-12.676, 'Species confirming'), (-12.724, 'Go confirming'), (-12.776, 'Established confirming'), (-12.871, 'Park confirming'), (-13.315, 'Night confirming'), (-13.542, 'Long confirming'), (-13.545, 'Fundamental confirming'), (-14.916, 'Island confirming')]\n"
     ]
    }
   ],
   "source": [
    "prefixes = [phrase +  ' ' + 'confirming' for phrase in first_phrases]\n",
    "prefixes.append('Before confirming')\n",
    "scores = [score_prefix('A positive PSA test has to be followed up with a biopsy or other procedures before cancer can be confirmed.', prefix) for prefix in prefixes]\n",
    "sorted_scores = sorted(((score, result) for score, result in scores), reverse=True)\n",
    "print(sorted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-3.136, 'Bradley left'), (-5.233, 'All of the left'), (-5.888, 'Famous left'), (-6.185, 'Once they left'), (-6.265, 'They left'), (-7.465, 'Yellowstone left'), (-7.637, 'Yellowstone National park was left'), (-7.967, 'Cats left'), (-8.051, 'The left'), (-8.051, 'The left'), (-8.051, 'The left'), (-8.244, 'All left'), (-8.53, 'Confirming left'), (-8.58, 'Once left'), (-8.601, 'Those left'), (-8.837, 'Park left'), (-9.027, 'Easter Island as long been left'), (-9.283, 'As left'), (-9.543, 'Our fundamental left'), (-9.662, 'Was left'), (-9.674, 'Those charasmatic left'), (-9.712, 'Before left'), (-9.712, 'Before left'), (-9.766, 'Charasmatic left'), (-9.794, 'Long left'), (-9.938, 'Go left'), (-9.954, 'Our left'), (-9.958, 'Species left'), (-10.063, 'Island left'), (-10.141, 'Been left'), (-10.346, 'Fundamental left'), (-10.514, 'Values left'), (-10.843, 'National left'), (-11.084, 'Night left'), (-11.29, 'Of left'), (-11.691, 'Easter left'), (-12.125, 'Established left')]\n"
     ]
    }
   ],
   "source": [
    "prefixes = [phrase +  ' ' + 'left' for phrase in first_phrases]\n",
    "prefixes.append('Bradley left')\n",
    "scores = [score_prefix('It was the first time in four years that a healthy Donovan did not start, and while he said he was in agreement with Bradley\\'s decision, Bradley left him on the bench again in the semifinals.', prefix) for prefix in prefixes]\n",
    "sorted_scores = sorted(((score, result) for score, result in scores), reverse=True)\n",
    "print(sorted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-3.612, 'All cats'), (-6.407, 'The cats'), (-6.407, 'The cats'), (-6.407, 'The cats'), (-7.088, 'All of the cats'), (-8.483, 'Those cats'), (-10.651, 'Our cats'), (-14.144, 'Famous cats'), (-14.892, 'Park cats'), (-15.543, 'Island cats'), (-15.994, 'National cats'), (-17.298, 'Night cats'), (-17.384, 'They cats'), (-18.878, 'Is cats'), (-19.004, 'Easter cats'), (-19.655, 'Established cats'), (-19.88, 'Before cats'), (-19.88, 'Before cats'), (-19.937, 'Been cats'), (-20.074, 'Fundamental cats'), (-20.11, 'Has cats'), (-20.299, 'Once cats'), (-20.451, 'Of cats'), (-20.742, 'Cats cats'), (-20.994, 'Was cats'), (-21.59, 'Day cats'), (-21.848, 'Species cats'), (-22.083, 'Long cats'), (-22.285, 'Individuals cats'), (-23.165, 'Confirming cats'), (-23.441, 'Go cats'), (-23.625, 'Yellowstone cats'), (-24.381, 'Held cats'), (-24.614, 'Values cats'), (-24.684, 'Once they cats'), (-25.977, '599 cats'), (-25.977, '599 cats'), (-27.819, 'Our fundamental cats'), (-35.927, 'Charasmatic cats'), (-37.3, 'Longmire cats'), (-39.419, 'Those charasmatic cats'), (-43.153, 'Easter Island has long been cats'), (-47.39, 'Yellowstone National Park was cats'), (-51.407, 'Longmire Day is cats')]\n"
     ]
    }
   ],
   "source": [
    "prefixes = [phrase +  ' ' + 'cats' for phrase in first_phrases]\n",
    "scores = [score_prefix('In my opinion, all of the cats are cool', prefix) for prefix in prefixes]\n",
    "sorted_scores = sorted(((score, result) for score, result in scores), reverse=True)\n",
    "print(sorted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['599', 'All', 'All of the', 'Been', 'Before', 'Cats', 'Charasmatic', 'Confirming', 'Day', 'Easter', 'Easter Island has long been', 'Established', 'Famous', 'Fundamental', 'Go', 'Has', 'Held', 'Individuals', 'Is', 'Island', 'Long', 'Longmire', 'Longmire Day is', 'National', 'Night', 'Of', 'Once', 'Once they', 'Our', 'Our fundamental', 'Park', 'Species', 'The', 'They', 'Those', 'Those charasmatic', 'Values', 'Was', 'Yellowstone', 'Yellowstone National Park was']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['All of the cats are great, in my opinion.',\n",
       " 'The night was dark and stormy.',\n",
       " \"Once they go, they won't be back.\",\n",
       " 'Easter Island has long been famous for the enormous stone statues erected by its prehistoric settlers.',\n",
       " \"Yellowstone National Park was established by the US government in 1972 as the world's first legislated effort at nature conservation.\",\n",
       " 'Before confirming cancer, a positive PSA text has to be followed up with a biopsy or other procedures.',\n",
       " \"Our fundamental values haven't changed, said University of Michigan President Mary Sue Coleman in a statement on the university's Web site.\",\n",
       " 'Those charasmatic species whose specieswide genetic diversity is very low are at the highest risk.',\n",
       " \"Longmire Day is held in the small town of Buffalo, Wyoming to celebrate the success of Johnson's novels.\",\n",
       " '599 individuals lived there at the 2006 census.']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    ('In my opinion, all of the cats are great.', 'All of the cats', 'cats'),\n",
    "    ('It was a dark and stormy night', 'The night', 'night'),\n",
    "    ('They won\\'t be back once they go.', 'Once they go', 'go'),\n",
    "    ('''Easter Island, the most remote place on Earth in terms of distance from other inhabited places, \n",
    "         has long been famous for the enormous stone statues erected by its prehistoric settlers.''', 'Easter Island has long been famous', 'famous'),\n",
    "    ('In 1972, the United States government established Yellowstone National Park as the world\\'s first legislated effort at nature conservation',\n",
    "        'Yellowstone National Park was established', 'established'),\n",
    "    ('A positive PSA test has to be followed up with a biopsy or other procedures before cancer can be confirmed.', 'Before confirming', 'confirming'),\n",
    "    ('University of Michigan President Mary Sue Coleman said in a statement on the university\\'s Web site, \"Our fundamental values haven\\'t changed.',\n",
    "        'Our fundamental values', 'values'),\n",
    "    ('At highest risk are those charasmatic species whose specieswide genetic diversity is very low.', 'Those charasmatic species', 'species'),\n",
    "     ('The success of Johnson\\'s novels is celebrated in an annual festival, called Longmire Day, held in the small town of Buffalo, Wyoming', 'Longmire Day is held', 'held'),\n",
    "    ('At the 2006 census, its population was 599', '599 individuals', 'individuals')\n",
    "]\n",
    "first_phrases = []\n",
    "for src, tgt, word in examples:\n",
    "    #tgt_words = tgt#.split()\n",
    "    #idx = tgt_words.index(word)\n",
    "    #words_before_tgt_word = tgt_words[:idx]\n",
    "    for w in tgt.rstrip('?.!,').split():\n",
    "        first_phrases.append(w.capitalize())\n",
    "    first_phrases.append(tgt[0: tgt.index(word)].strip())\n",
    "print(sorted(set(first_phrases)))\n",
    "\n",
    "paraphrases = [\"All of the cats are great, in my opinion.\",\n",
    "               \"The night was dark and stormy.\",\n",
    "               \"Once they go, they won't be back.\",\n",
    "               \"Easter Island has long been famous for the enormous stone statues erected by its prehistoric settlers.\",\n",
    "               \"Yellowstone National Park was established by the US government in 1972 as the world\\'s first legislated effort at nature conservation.\",\n",
    "               \"Before confirming cancer, a positive PSA text has to be followed up with a biopsy or other procedures.\",\n",
    "               \"Our fundamental values haven't changed, said University of Michigan President Mary Sue Coleman in a statement on the university's Web site.\",\n",
    "               \"Those charasmatic species whose specieswide genetic diversity is very low are at the highest risk.\",\n",
    "               \"Longmire Day is held in the small town of Buffalo, Wyoming to celebrate the success of Johnson's novels.\",\n",
    "               \"599 individuals lived there at the 2006 census.\"\n",
    "              ]\n",
    "paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranks = []\n",
    "for src, tgt, word in examples:\n",
    "    prefixes = [phrase +  ' ' + word for phrase in first_phrases]\n",
    "    scores = [score_prefix(src, prefix) for prefix in prefixes]\n",
    "    # compute rank of actual prefix in sorted scores\n",
    "    sorted_scores = sorted(((score, result) for score, result in scores), reverse=True)\n",
    "    rank = [y[1] for y in sorted_scores].index(tgt) + 1\n",
    "    ranks.append((tgt, rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1e\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >original</th>        <th class=\"col_heading level0 col1\" >expected paraphrase</th>        <th class=\"col_heading level0 col2\" >expected prefix</th>        <th class=\"col_heading level0 col3\" >word</th>        <th class=\"col_heading level0 col4\" >rank of expected prefix</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow0_col0\" class=\"data row0 col0\" >In my opinion, all of the cats are great.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow0_col1\" class=\"data row0 col1\" >All of the cats are great, in my opinion.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow0_col2\" class=\"data row0 col2\" >All of the cats</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow0_col3\" class=\"data row0 col3\" >cats</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow0_col4\" class=\"data row0 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow1_col0\" class=\"data row1 col0\" >It was a dark and stormy night</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow1_col1\" class=\"data row1 col1\" >The night was dark and stormy.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow1_col2\" class=\"data row1 col2\" >The night</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow1_col3\" class=\"data row1 col3\" >night</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow1_col4\" class=\"data row1 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow2_col0\" class=\"data row2 col0\" >They won't be back once they go.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow2_col1\" class=\"data row2 col1\" >Once they go, they won't be back.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow2_col2\" class=\"data row2 col2\" >Once they go</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow2_col3\" class=\"data row2 col3\" >go</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow2_col4\" class=\"data row2 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow3_col0\" class=\"data row3 col0\" >Easter Island, the most remote place on Earth in terms of distance from other inhabited places, \n",
       "         has long been famous for the enormous stone statues erected by its prehistoric settlers.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow3_col1\" class=\"data row3 col1\" >Easter Island has long been famous for the enormous stone statues erected by its prehistoric settlers.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow3_col2\" class=\"data row3 col2\" >Easter Island has long been famous</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow3_col3\" class=\"data row3 col3\" >famous</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow3_col4\" class=\"data row3 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow4_col0\" class=\"data row4 col0\" >In 1972, the United States government established Yellowstone National Park as the world's first legislated effort at nature conservation</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow4_col1\" class=\"data row4 col1\" >Yellowstone National Park was established by the US government in 1972 as the world's first legislated effort at nature conservation.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow4_col2\" class=\"data row4 col2\" >Yellowstone National Park was established</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow4_col3\" class=\"data row4 col3\" >established</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow4_col4\" class=\"data row4 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow5_col0\" class=\"data row5 col0\" >A positive PSA test has to be followed up with a biopsy or other procedures before cancer can be confirmed.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow5_col1\" class=\"data row5 col1\" >Before confirming cancer, a positive PSA text has to be followed up with a biopsy or other procedures.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow5_col2\" class=\"data row5 col2\" >Before confirming</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow5_col3\" class=\"data row5 col3\" >confirming</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow5_col4\" class=\"data row5 col4\" >11</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow6_col0\" class=\"data row6 col0\" >University of Michigan President Mary Sue Coleman said in a statement on the university's Web site, \"Our fundamental values haven't changed.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow6_col1\" class=\"data row6 col1\" >Our fundamental values haven't changed, said University of Michigan President Mary Sue Coleman in a statement on the university's Web site.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow6_col2\" class=\"data row6 col2\" >Our fundamental values</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow6_col3\" class=\"data row6 col3\" >values</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow6_col4\" class=\"data row6 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow7_col0\" class=\"data row7 col0\" >At highest risk are those charasmatic species whose specieswide genetic diversity is very low.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow7_col1\" class=\"data row7 col1\" >Those charasmatic species whose specieswide genetic diversity is very low are at the highest risk.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow7_col2\" class=\"data row7 col2\" >Those charasmatic species</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow7_col3\" class=\"data row7 col3\" >species</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow7_col4\" class=\"data row7 col4\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow8_col0\" class=\"data row8 col0\" >The success of Johnson's novels is celebrated in an annual festival, called Longmire Day, held in the small town of Buffalo, Wyoming</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow8_col1\" class=\"data row8 col1\" >Longmire Day is held in the small town of Buffalo, Wyoming to celebrate the success of Johnson's novels.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow8_col2\" class=\"data row8 col2\" >Longmire Day is held</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow8_col3\" class=\"data row8 col3\" >held</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow8_col4\" class=\"data row8 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow9_col0\" class=\"data row9 col0\" >At the 2006 census, its population was 599</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow9_col1\" class=\"data row9 col1\" >599 individuals lived there at the 2006 census.</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow9_col2\" class=\"data row9 col2\" >599 individuals</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow9_col3\" class=\"data row9 col3\" >individuals</td>\n",
       "                        <td id=\"T_cd981ed2_bf23_11ea_8fe3_c85b76eabc1erow9_col4\" class=\"data row9 col4\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25286847788>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'original': [ex[0] for ex in examples],\n",
    "              'expected paraphrase': paraphrases,\n",
    "              'expected prefix': [ex[1] for ex in examples],\n",
    "              'word': [ex[2] for ex in examples],\n",
    "              'rank of expected prefix': [el[1] for el in ranks]}).style.hide_index()\n",
    "# df = df.style.set_properties(**{'text-align': 'left'})\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.colheader_justify\",\"left\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.34, 'Those charasmatic species'),\n",
       " (-1.376, 'Charasmatic species'),\n",
       " (-1.947, 'Those species'),\n",
       " (-2.509, 'Famous species'),\n",
       " (-2.753, 'All of the species'),\n",
       " (-3.105, 'The species'),\n",
       " (-3.105, 'The species'),\n",
       " (-3.105, 'The species'),\n",
       " (-4.239, 'All species'),\n",
       " (-4.653, 'Our species'),\n",
       " (-6.252, 'Yellowstone species'),\n",
       " (-6.478, 'Confirming species'),\n",
       " (-6.546, 'As species'),\n",
       " (-6.962, 'Our fundamental species'),\n",
       " (-7.115, 'Species species'),\n",
       " (-7.127, 'Park species'),\n",
       " (-7.172, 'Fundamental species'),\n",
       " (-7.332, 'Cats species'),\n",
       " (-7.514, 'Once they species'),\n",
       " (-7.794, 'Of species'),\n",
       " (-7.826, 'They species'),\n",
       " (-7.84, 'Once species'),\n",
       " (-7.946, 'National species'),\n",
       " (-8.148, 'Yellowstone National park was species'),\n",
       " (-8.411, 'Established species'),\n",
       " (-8.44, 'Easter Island as long been species'),\n",
       " (-8.538, 'Before species'),\n",
       " (-8.538, 'Before species'),\n",
       " (-8.56, 'Island species'),\n",
       " (-9.178, 'Was species'),\n",
       " (-9.371, 'Easter species'),\n",
       " (-9.942, 'Long species'),\n",
       " (-10.228, 'Night species'),\n",
       " (-10.407, 'Been species'),\n",
       " (-10.811, 'Go species'),\n",
       " (-11.901, 'Values species')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 9, 1, 1]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.840</td>\n",
       "      <td>The night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.539</td>\n",
       "      <td>All night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-4.809</td>\n",
       "      <td>Stormy night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.843</td>\n",
       "      <td>My night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.255</td>\n",
       "      <td>Was night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-5.375</td>\n",
       "      <td>Dark night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-5.773</td>\n",
       "      <td>And night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.852</td>\n",
       "      <td>Great, night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-6.511</td>\n",
       "      <td>Night night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.621</td>\n",
       "      <td>In night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.173</td>\n",
       "      <td>Cats night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-10.187</td>\n",
       "      <td>Opinion night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.310</td>\n",
       "      <td>Are night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    scores       sentences\n",
       "7   -2.840       The night\n",
       "0   -4.539       All night\n",
       "12  -4.809    Stormy night\n",
       "5   -4.843        My night\n",
       "9   -5.255       Was night\n",
       "10  -5.375      Dark night\n",
       "11  -5.773       And night\n",
       "3   -5.852    Great, night\n",
       "8   -6.511     Night night\n",
       "4   -6.621        In night\n",
       "1   -7.173      Cats night\n",
       "6  -10.187   Opinion night\n",
       "2  -10.310       Are night"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'scores': [prefix[0] for prefix in scores], 'sentences': [prefix[1] for prefix in scores]}).sort_values('scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-2.84, ' The night'),\n",
       " (-4.539, ' All night'),\n",
       " (-4.809, ' Stormy night'),\n",
       " (-4.843, ' My night'),\n",
       " (-5.255, ' Was night'),\n",
       " (-5.375, ' Dark night'),\n",
       " (-5.773, ' And night'),\n",
       " (-5.852, ' Great, night'),\n",
       " (-6.511, ' Night night'),\n",
       " (-6.621, ' In night'),\n",
       " (-7.173, ' Cats night'),\n",
       " (-10.187, ' Opinion night'),\n",
       " (-10.31, ' Are night')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(((score, result) for score, result in scores), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(' ' + 'All cats are great, info my opinion').index(' ' + 'in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "print('a\\nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\\nb\n"
     ]
    }
   ],
   "source": [
    "print(r'a\\nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(20, 25), match='great'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\bgreat\\b', 'All of the cats are great, opinion.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The cats are all great, in my opinion.\n",
      "-11.56362009048462\n",
      "\n",
      " All cats are great, in my opinion.\n",
      "-7.648155689239502\n",
      "\n",
      " cats are great, in my opinion.\n",
      "-15.431335926055908\n",
      "\n",
      " ⁇  in cats are great.\n",
      "-33.81710910797119\n",
      "\n",
      " My cats are all great.\n",
      "-18.766332626342773\n",
      "\n",
      " Opinion, cats are all great.\n",
      "-20.298365592956543\n",
      "\n",
      " All cats are great, in my opinion.\n",
      "-7.648155689239502\n",
      "\n",
      " Cats cats are great, in my opinion.\n",
      "-25.229657649993896\n",
      "\n",
      " Are cats great?\n",
      "-17.362116813659668\n",
      "\n",
      " Great. cats are all great.\n",
      "-24.31656265258789\n",
      "\n",
      "Most likely:   All cats are great, in my opinion.\n"
     ]
    }
   ],
   "source": [
    "english = \">>es<<In my opinion, all cats are great.\"\n",
    "engbatch = en_ROMANCE_tokenizer.prepare_translation_batch([english])\n",
    "eng_to_spanish = en_ROMANCE.generate(**engbatch)\n",
    "machine_translation = en_ROMANCE_tokenizer.decode(eng_to_spanish[0])\n",
    "\n",
    "start = \"cats\"\n",
    "\n",
    "tokenizer = ROMANCE_en_tokenizer\n",
    "model = ROMANCE_en\n",
    "\n",
    "first_words = [\"The\", \"All\", \"\"]\n",
    "wordlist = english.split(' ')\n",
    "for word in wordlist:\n",
    "    first_words.append(word.capitalize())\n",
    "first_words\n",
    "    \n",
    "results = []\n",
    "scores = []\n",
    "MAX_LENGTH = 100\n",
    "    \n",
    "for word in first_words:\n",
    "    join_prefix_str = word + \" \" + start\n",
    "    tokenized_prefix = tokenizer.convert_tokens_to_ids(en_ROMANCE_tokenizer.tokenize(join_prefix_str.strip()))\n",
    "    prefix = torch.LongTensor(tokenized_prefix)\n",
    "#     tokenized_prefix = tokenizer.convert_tokens_to_ids(en_ROMANCE_tokenizer.tokenize(start))\n",
    "#     prefix = torch.LongTensor(tokenized_prefix)\n",
    "\n",
    "    batch = tokenizer.prepare_translation_batch([machine_translation.replace(\"<pad> \", '')])\n",
    "    english_encoded = model.get_encoder()(**batch)\n",
    "    decoder_start_token = model.config.decoder_start_token_id\n",
    "    # pylint: disable=E1101\n",
    "    partial_decode = torch.LongTensor([decoder_start_token]).unsqueeze(0)\n",
    "    past = (english_encoded, None)\n",
    "    # pylint: enable=E1101\n",
    "\n",
    "    num_tokens_generated = 0\n",
    "    prediction_list = []\n",
    "    total = 0\n",
    "    #stop when </s> token generated, or max num tokens exceded (just in case)\n",
    "    while True:\n",
    "        model_inputs = model.prepare_inputs_for_generation(\n",
    "        partial_decode, past=past, attention_mask=batch['attention_mask'], use_cache=model.config.use_cache\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model(**model_inputs)\n",
    "\n",
    "        next_token_logits = model_outputs[0][:, -1, :]\n",
    "        past = model_outputs[1]\n",
    "\n",
    "        #start with user inputted beginning\n",
    "        if num_tokens_generated < len(prefix):\n",
    "            next_token_to_add = prefix[num_tokens_generated]\n",
    "        else:\n",
    "            break\n",
    "#             next_token_to_add = next_token_logits[0].argmax()\n",
    "\n",
    "        next_token_logprobs = next_token_logits - next_token_logits.logsumexp(1, True)\n",
    "        score = next_token_logprobs[0][next_token_to_add].item()\n",
    "\n",
    "        total += score\n",
    "\n",
    "        #add new token to tokens so far\n",
    "        partial_decode = torch.cat((partial_decode, next_token_to_add.unsqueeze(0).unsqueeze(0)), -1)\n",
    "        num_tokens_generated+= 1\n",
    "\n",
    "        if next_token_to_add.item() == 0 or not (num_tokens_generated < MAX_LENGTH):\n",
    "            break\n",
    "\n",
    "    #list of tokens used to display sentence\n",
    "    decoded_tokens = [sub.replace('\\u2581', '\\u00a0') for sub in tokenizer.convert_ids_to_tokens(partial_decode[0])]\n",
    "    decoded_tokens.remove(\"<pad>\")\n",
    "\n",
    "    final = tokenizer.decode(partial_decode[0]).replace(\"<pad>\", '')\n",
    "    score = round(total/(len(decoded_tokens)), 3)\n",
    "    results.append(final)\n",
    "    scores.append(score)\n",
    "\n",
    "    print(\"\\n\" + final)\n",
    "    print(total)\n",
    "\n",
    "ind = scores.index(max(scores))\n",
    "winner = results[ind]\n",
    "print(\"\\nMost likely: \", winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '>>es<<in', 'All', 'Are', 'Cats', 'Great.', 'My', 'Opinion,', 'The']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(first_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.765, ' All cats are great, in my opinion.'),\n",
       " (-0.765, ' All cats are great, in my opinion.'),\n",
       " (-1.051, ' The cats are all great, in my opinion.'),\n",
       " (-1.715, ' cats are great, in my opinion.'),\n",
       " (-2.294, ' Cats cats are great, in my opinion.'),\n",
       " (-2.537, ' Opinion, cats are all great.'),\n",
       " (-2.681, ' My cats are all great.'),\n",
       " (-3.04, ' Great. cats are all great.'),\n",
       " (-3.472, ' Are cats great?'),\n",
       " (-4.831, ' ⁇  in cats are great.')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(((score, result) for score, result in zip(scores, results)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4.831, ' ⁇  in cats are great.'),\n",
       " (-3.472, ' Are cats great?'),\n",
       " (-3.04, ' Great. cats are all great.'),\n",
       " (-2.681, ' My cats are all great.'),\n",
       " (-2.537, ' Opinion, cats are all great.'),\n",
       " (-2.294, ' Cats cats are great, in my opinion.'),\n",
       " (-1.715, ' cats are great, in my opinion.'),\n",
       " (-1.051, ' The cats are all great, in my opinion.'),\n",
       " (-0.765, ' All cats are great, in my opinion.'),\n",
       " (-0.765, ' All cats are great, in my opinion.')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(scores, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.765, ' All cats are great, in my opinion.'),\n",
       " (-0.765, ' All cats are great, in my opinion.'),\n",
       " (-1.051, ' The cats are all great, in my opinion.'),\n",
       " (-1.715, ' cats are great, in my opinion.'),\n",
       " (-2.294, ' Cats cats are great, in my opinion.'),\n",
       " (-2.537, ' Opinion, cats are all great.'),\n",
       " (-2.681, ' My cats are all great.'),\n",
       " (-3.04, ' Great. cats are all great.'),\n",
       " (-3.472, ' Are cats great?'),\n",
       " (-4.831, ' ⁇  in cats are great.')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(scores[ind], results[ind]) for ind in torch.tensor(scores).topk(len(scores)).indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[65000]])\n",
      "0 :  tensor(100)\n",
      "tensor([[65000,   100]])\n",
      "tensor([[65000,   100,  4997]])\n",
      "tensor([[65000,   100,  4997,   531]])\n",
      "tensor([[65000,   100,  4997,   531,   231]])\n",
      "tensor([[65000,   100,  4997,   531,   231, 11023]])\n",
      "tensor([[65000,   100,  4997,   531,   231, 11023,    32]])\n",
      "tensor([[65000,   100,  4997,   531,   231, 11023,    32,   805]])\n",
      "tensor([[65000,   100,  4997,   531,   231, 11023,    32,   805,  6386]])\n",
      "tensor([[65000,   100,  4997,   531,   231, 11023,    32,   805,  6386,   570]])\n",
      "tensor([[65000,   100,  4997,   531,   231, 11023,    32,   805,  6386,   570,\n",
      "          3301]])\n",
      "tensor([[65000,   100,  4997,   531,   231, 11023,    32,   805,  6386,   570,\n",
      "          3301,     3]])\n",
      " La noche era oscura y tempestuosa.\n",
      "['<pad>', '\\xa0La', '\\xa0noche', '\\xa0era', '\\xa0os', 'cura', '\\xa0y', '\\xa0tem', 'pes', 'tu', 'osa', '.', '</s>']\n",
      "[['\\xa0Era', '\\xa0Fue', '\\xa0Es', '\\xa0Ha', '\\xa0Una'], ['\\xa0noche', '\\xa0tarde', '\\xa0oscuridad', '\\xa0verdad', '\\xa0vela'], ['\\xa0era', '\\xa0fue', '\\xa0estaba', '\\xa0estuvo', '\\xa0es'], ['\\xa0os', '\\xa0som', '\\xa0tem', '\\xa0de', '\\xa0muy'], ['cura', 'cure', 'cur', 'ca', 'cu'], ['\\xa0y', ',', '.', '\\xa0e', '</s>'], ['\\xa0tem', '\\xa0tormenta', '\\xa0tor', '\\xa0os', '\\xa0tur'], ['pes', 'p', 'pra', 'pla', 'pl'], ['tu', 'ta', 'tiva', 'tada', 'table'], ['osa', 'oso', 'osas', 'ada', 'osamente'], ['.', '</s>', ',', '...', '!'], ['</s>', '.', '<pad>', '\\xa0¿', '\\xa0-']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The night was dark and stormy.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = en_ROMANCE_tokenizer\n",
    "model = en_ROMANCE\n",
    "#tokenizer = ROMANCE_en_tokenizer\n",
    "#model = ROMANCE_en\n",
    "\n",
    "\n",
    "english = \">>es<<It was a dark and stormy night\"\n",
    "batch = tokenizer.prepare_translation_batch([english])\n",
    "english_encoded = model.get_encoder()(**batch)\n",
    "decoder_start_token = model.config.decoder_start_token_id\n",
    "\n",
    "starting_word = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"La\"))\n",
    "#starting_word = tokenizer.encode(\"A la\")\n",
    "\n",
    "partial_decode = torch.LongTensor([decoder_start_token]).unsqueeze(0)\n",
    "past = (english_encoded, None)\n",
    "\n",
    "prefix = torch.LongTensor(starting_word)\n",
    "#prefix = torch.LongTensor(tokenizer.convert_tokens_to_ids(\"A la\".replace(' ', '▁').split('▁')))\n",
    "#prefix = torch.LongTensor(tokenizer.encode(\"A la\"))\n",
    "#prefix = torch.LongTensor(tokenizer.encode(\"A▁la▁\"))\n",
    "next_token_to_add = torch.tensor(1)\n",
    "x = 0\n",
    "\n",
    "prediction_list = []\n",
    "\n",
    "while next_token_to_add.item() != 0 and x < 100:\n",
    "    print(partial_decode)\n",
    "    model_inputs = model.prepare_inputs_for_generation(\n",
    "    partial_decode, past=past, attention_mask=batch['attention_mask'], use_cache=model.config.use_cache\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model_outputs = model(**model_inputs)\n",
    "\n",
    "    next_token_logits = model_outputs[0][:, -1, :]\n",
    "    past = model_outputs[1]\n",
    "    \n",
    "    if x < len(prefix):\n",
    "        next_token_to_add = prefix[x]\n",
    "        print(x, \": \", next_token_to_add)\n",
    "    else:\n",
    "        next_token_to_add = next_token_logits[0].argmax()\n",
    "\n",
    "    decoded_predictions = []\n",
    "    for tok in next_token_logits[0].topk(5).indices:\n",
    "        decoded_predictions.append(tokenizer.convert_ids_to_tokens(tok.item()).replace('\\u2581', '\\u00a0'))\n",
    "    \n",
    "    prediction_list.append(decoded_predictions)\n",
    "    \n",
    "    partial_decode = torch.cat((partial_decode, next_token_to_add.unsqueeze(0).unsqueeze(0)), -1)\n",
    "    x += 1\n",
    "    \n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(partial_decode[0])\n",
    "\n",
    "decoded_tokens = [sub.replace('\\u2581', '\\u00a0') for sub in tokenizer.convert_ids_to_tokens(partial_decode[0])] \n",
    "\n",
    "final = tokenizer.decode(partial_decode[0]).split(\"<pad>\")[1]\n",
    "print(final)\n",
    "print(decoded_tokens)\n",
    "print(prediction_list)\n",
    "\n",
    "batch2 = ROMANCE_en_tokenizer.prepare_translation_batch([\">>en<< \" + final])\n",
    "spanish_to_english = ROMANCE_en.generate(**batch2)\n",
    "new_english = ROMANCE_en_tokenizer.decode(spanish_to_english[0]).split(\"<pad>\")[1]\n",
    "\n",
    "new_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fue un día oscura, tempestuoso\n",
      " Era un día oscuro, tempunático\n",
      " Era una oscuridad y una noche tormenta.\n",
      " Era un noche sombrías, tempunática\n",
      " Fue un día oscura y tormenta.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Fue un día oscura, tempestuoso',\n",
       " ' Era un día oscuro, tempunático',\n",
       " ' Era una oscuridad y una noche tormenta.',\n",
       " ' Era un noche sombrías, tempunática',\n",
       " ' Fue un día oscura y tormenta.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = en_ROMANCE_tokenizer\n",
    "model = en_ROMANCE\n",
    "\n",
    "english = \">>es<<It was a dark and stormy night\"\n",
    "batch = tokenizer.prepare_translation_batch([english])\n",
    "english_encoded = model.get_encoder()(**batch)\n",
    "decoder_start_token = model.config.decoder_start_token_id\n",
    "\n",
    "starting_word = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"\"))\n",
    "prefix = torch.LongTensor(starting_word)\n",
    "prediction_list = []\n",
    "alternatives = []\n",
    "for x in range(0, 5):\n",
    "\n",
    "    past = (english_encoded, None)\n",
    "   \n",
    "    partial_decode = torch.LongTensor([decoder_start_token]).unsqueeze(0)\n",
    "    y = 0\n",
    "    next_token_to_add = torch.tensor(1)\n",
    "    while next_token_to_add.item() != 0 and y < 100:    \n",
    "        model_inputs = model.prepare_inputs_for_generation(\n",
    "        partial_decode, past=past, attention_mask=batch['attention_mask'], use_cache=model.config.use_cache\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model(**model_inputs)\n",
    "        next_token_logits = model_outputs[0][:, -1, :]\n",
    "        past = model_outputs[1]\n",
    "\n",
    "        if y < len(prefix):\n",
    "            next_token_to_add = prefix[y]\n",
    "        else:\n",
    "            next_token_to_add = next_token_logits[0].topk(4).indices[random.randint(0, 1)]\n",
    "        decoded_predictions = []\n",
    "        for tok in next_token_logits[0].topk(5).indices:\n",
    "            decoded_predictions.append(tokenizer.convert_ids_to_tokens(tok.item()).replace('\\u2581', '\\u00a0'))\n",
    "\n",
    "        prediction_list.append(decoded_predictions)\n",
    "        partial_decode = torch.cat((partial_decode, next_token_to_add.unsqueeze(0).unsqueeze(0)), -1)\n",
    "        y += 1\n",
    "\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(partial_decode[0])\n",
    "\n",
    "    final = tokenizer.decode(partial_decode[0]).split(\"<pad>\")[1]\n",
    "    print(final)\n",
    "    alternatives.append(final)\n",
    "    \n",
    "alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' No seas tan malo.',\n",
       " ' No seas tan mala.',\n",
       " ' No seas tan malvado.',\n",
       " ' No seas tan cruel.',\n",
       " ' No seas tan malvada.',\n",
       " ' No seas tan mezquino.',\n",
       " ' No seas tan desagradable.',\n",
       " ' No seas tan mezquina.',\n",
       " ' No seas malvado.',\n",
       " ' No seáis tan malos.',\n",
       " ' No seas tan malos.',\n",
       " ' No seas tan repugnante.',\n",
       " ' No seas tan miserable.',\n",
       " ' No seas malvada.',\n",
       " ' No seáis tan malvados.',\n",
       " ' No seas muy mala.',\n",
       " ' - No seas tan malo.',\n",
       " ' - No seas tan mala.',\n",
       " ' No seas muy malo.',\n",
       " ' ¡No seas tan mala!',\n",
       " ' ¡No seas tan malo!',\n",
       " ' - No seas tan malvado.',\n",
       " ' No sean tan malos.',\n",
       " ' No seas así de malo.',\n",
       " ' No seas muy malvado.',\n",
       " ' No te pongas tan mal.',\n",
       " ' No seas tan mesquino.',\n",
       " ' No sea tan malo.',\n",
       " ' No te pongas mal.',\n",
       " ' No seas así de mala.',\n",
       " ' No seas tan méchanta.',\n",
       " ' No seas así de malvado.',\n",
       " ' ¡No seas tan malvada!',\n",
       " ' No seas tan mesquita.',\n",
       " ' No sea tan malvado.',\n",
       " ' No seas mala.',\n",
       " ' ¡No seas tan malvado!',\n",
       " ' - No seas tan malvada.',\n",
       " ' No sean tan malvados.',\n",
       " ' - No seas tan cruel.',\n",
       " ' No seas muy malvada.',\n",
       " ' No te pongas tan malvado.',\n",
       " ' No seas tan vil.',\n",
       " ' No seas tan maldad.',\n",
       " ' No seáis tan crueles.',\n",
       " ' ¡No seas tan cruel!',\n",
       " ' No te pongas tan malo.',\n",
       " ' No seas muy cruel.',\n",
       " ' No seas tan mezquinta.',\n",
       " ' No seas tan magro.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = en_ROMANCE_tokenizer\n",
    "model = en_ROMANCE\n",
    "\n",
    "english = \">>es<<Don't be so mean.\"\n",
    "batch = tokenizer.prepare_translation_batch([english])\n",
    "                                            \n",
    "eng_to_spanish = model.generate(num_beams=50, num_return_sequences=50, **batch)\n",
    "\n",
    "translations = []\n",
    "for x in range(0, 50):\n",
    "    translations.append(tokenizer.decode(eng_to_spanish[x]).split(\"<pad>\")[1])\n",
    "\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. I believe this is the wrong store.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english = \">>es<<I think maybe this is the wrong store.\"\n",
    "batch = tokenizer.prepare_translation_batch([english])\n",
    "                                            \n",
    "spanish = model.generate(**batch)\n",
    "\n",
    "batch = ROMANCE_en_tokenizer.prepare_translation_batch([\">>en<<\" + tokenizer.decode(spanish[0]).replace(\"<pad>\", '')])\n",
    "back_to_english = ROMANCE_en.generate(**batch)\n",
    "machine_translation = ROMANCE_en_tokenizer.decode(back_to_english[0]).replace(\"<pad>\", '')\n",
    "\n",
    "spanish_encoded = ROMANCE_en.get_encoder()(**batch)\n",
    "decoder_start_token = ROMANCE_en.config.decoder_start_token_id\n",
    "# pylint: disable=E1101\n",
    "partial_decode = torch.LongTensor([decoder_start_token]).unsqueeze(0)\n",
    "past = (spanish_encoded, None)\n",
    "# pylint: enable=E1101\n",
    "next_token_to_add = torch.tensor(1)\n",
    "x = 0\n",
    "\n",
    "prediction_list = []\n",
    "\n",
    "while next_token_to_add.item() != 0 and x < 100:\n",
    "    model_inputs = ROMANCE_en.prepare_inputs_for_generation(\n",
    "    partial_decode, past=past, attention_mask=batch['attention_mask'], use_cache=ROMANCE_en.config.use_cache\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model_outputs = ROMANCE_en(**model_inputs)\n",
    "\n",
    "    next_token_logits = model_outputs[0][:, -1, :]\n",
    "    past = model_outputs[1]\n",
    "   \n",
    "    if x == 3:\n",
    "        next_token_to_add = next_token_logits[0].topk(4).indices[1]\n",
    "    else:\n",
    "        next_token_to_add= next_token_logits[0].argmax()\n",
    "    decoded_predictions = []\n",
    "    for tok in next_token_logits[0].topk(10).indices:\n",
    "        decoded_predictions.append(ROMANCE_en_tokenizer.convert_ids_to_tokens(tok.item()).replace('\\u2581', '\\u00a0'))\n",
    "\n",
    "    prediction_list.append(decoded_predictions)\n",
    "\n",
    "    partial_decode = torch.cat((partial_decode, next_token_to_add.unsqueeze(0).unsqueeze(0)), -1)\n",
    "    x+= 1\n",
    "\n",
    "decoded_tokens = [sub.replace('\\u2581', '\\u00a0') for sub in ROMANCE_en_tokenizer.convert_ids_to_tokens(partial_decode[0])]\n",
    "decoded_tokens.remove(\"<pad>\")\n",
    "final = ROMANCE_en_tokenizer.decode(partial_decode[0]).split(\"<pad>\")[1]\n",
    "\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
